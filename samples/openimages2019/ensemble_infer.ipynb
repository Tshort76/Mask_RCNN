{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T20:04:40.042820Z",
     "start_time": "2019-08-27T20:04:37.047885Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import skimage\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "from openimages2019 import setup as st\n",
    "from openimages2019 import utils as u\n",
    "\n",
    "from skimage.draw import rectangle\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"../data\")\n",
    "\n",
    "#Make GPUs visible\n",
    "!export HIP_VISIBLE_DEVICES=0,1,2,3\n",
    "\n",
    "\n",
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition the classes according to frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T20:05:37.816418Z",
     "start_time": "2019-08-27T20:04:42.526253Z"
    }
   },
   "outputs": [],
   "source": [
    "class_sets = st.partition_classes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T20:05:37.836405Z",
     "start_time": "2019-08-27T20:05:37.820279Z"
    }
   },
   "outputs": [],
   "source": [
    "class TrainConfig(Config):\n",
    "    \n",
    "    NAME = \"kaggle\"\n",
    "    GPU_COUNT = 2\n",
    "    IMAGES_PER_GPU = 2\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    STEPS_PER_EPOCH = 500\n",
    "    \n",
    "    \n",
    "def get_infer_model(config, model_path=None):\n",
    "    inf_model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=MODEL_DIR)\n",
    "\n",
    "    if model_path is None:\n",
    "        model_path = inf_model.find_last()\n",
    "        \n",
    "    inf_model.load_weights(model_path, by_name=True)\n",
    "    \n",
    "    return inf_model\n",
    "\n",
    "\n",
    "def load_member_models(model_paths, class_sets, images_per_gpu=2):\n",
    "    models = []\n",
    "\n",
    "    for i,mpath in enumerate(model_paths):\n",
    "\n",
    "        class KaggleConfig(TrainConfig):\n",
    "            NUM_CLASSES = len(class_sets[i])+ 1 # + 1 for background class\n",
    "\n",
    "        class InferenceConfig(KaggleConfig):\n",
    "            GPU_COUNT = 1\n",
    "            IMAGES_PER_GPU = images_per_gpu \n",
    "\n",
    "        inf_config = InferenceConfig()\n",
    "\n",
    "        model = get_infer_model(inf_config,model_path=mpath)\n",
    "        \n",
    "        models.append(model)\n",
    "        \n",
    "    return models\n",
    "\n",
    "\n",
    "def assemble(ind_results, iou_threshold=0.3):\n",
    "    \"\"\" Combines the results from many different models across a single images.  Uses NMS to handle overlaps\"\"\"\n",
    "\n",
    "    classes = np.concatenate([x['class_ids'] for x in ind_results])\n",
    "    scores = np.concatenate([x['scores'] for x in ind_results])\n",
    "\n",
    "    rois = np.concatenate([x['rois'] for x in ind_results],axis = 0)\n",
    "\n",
    "    #TODO just to display stuff ... not needed here\n",
    "    masks = np.concatenate([x['masks'] for x in ind_results],axis = 2)\n",
    "\n",
    "    to_keep = utils.non_max_suppression(rois, scores, iou_threshold)\n",
    "\n",
    "    return {'class_ids' : classes[to_keep], 'rois' : rois[to_keep],\n",
    "            'scores' : scores[to_keep], 'masks' : masks[:,:,to_keep]}\n",
    "\n",
    "\n",
    "def ensemble_detect(models, images, batch_size, id_offsets):\n",
    "    \"\"\"\n",
    "    \n",
    "    For each model, run inference on image batches.  Then groups inference results by image and \n",
    "    applys non maximum suppression (via assemble method) to each group.\n",
    "    \n",
    "    \"\"\"\n",
    "    all_results = [[] for x in images]\n",
    "\n",
    "    for midx,model in enumerate(models):\n",
    "\n",
    "        results = []\n",
    "        \n",
    "        # Have to do this because of model.detect batch size assertion\n",
    "        for j in range(0,len(images),batch_size):\n",
    "            results += model.detect(images[j:j+batch_size], verbose=0)\n",
    "\n",
    "        for i in range(len(results)):\n",
    "            r = results[i]\n",
    "\n",
    "            r['model_id'] = midx\n",
    "            r['class_ids'] += id_offsets[midx]\n",
    "\n",
    "            all_results[i].append(r)\n",
    "            \n",
    "    return [assemble(x) for x in all_results]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Member model label ids --> ensemble model label ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T20:05:37.852489Z",
     "start_time": "2019-08-27T20:05:37.838699Z"
    }
   },
   "outputs": [],
   "source": [
    "background = ['/mnull','Background']\n",
    "    \n",
    "z = [np.insert(cset[['LabelName','LabelDescription']].values,0,background,axis=0) for cset in class_sets]\n",
    "\n",
    "omni_class_set = pd.DataFrame(np.concatenate(z),columns=['LabelName','LabelDescription'])\n",
    "omni_class_set['LabelID'] = omni_class_set.index\n",
    "\n",
    "id_offsets = omni_class_set[omni_class_set['LabelName'] == '/mnull'].index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T20:06:54.880520Z",
     "start_time": "2019-08-27T20:05:37.854313Z"
    }
   },
   "outputs": [],
   "source": [
    "# rel_model_paths = ['kaggle20190815T2120/mask_rcnn_kaggle_0025.h5','kaggle20190815T2229/mask_rcnn_kaggle_0025.h5',\n",
    "#                'kaggle20190815T2347/mask_rcnn_kaggle_0025.h5','kaggle20190816T0115/mask_rcnn_kaggle_0025.h5',\n",
    "#                'kaggle20190816T0256/mask_rcnn_kaggle_0025.h5','kaggle20190816T0441/mask_rcnn_kaggle_0100.h5']\n",
    "\n",
    "\n",
    "# model_paths = [os.path.join(MODEL_DIR, mpath) for mpath in rel_model_paths]\n",
    "\n",
    "model_paths = [os.path.join(DATA_DIR,'models','cset_' + str(i) + '_model.h5') for i in range(6)]\n",
    "\n",
    "models = load_member_models(model_paths, class_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Run detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:25:10.898020Z",
     "start_time": "2019-08-20T22:24:35.257122Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img = skimage.io.imread(os.path.join(DATA_DIR, 'train/2fef4dd2f83feb18.jpg'))\n",
    "img2 = skimage.io.imread(os.path.join(DATA_DIR, 'train/55dee1384cd565ee.jpg'))\n",
    "\n",
    "images = [img,img2]\n",
    "\n",
    "detected = ensemble_detect(models, images,2, id_offsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:30:07.529514Z",
     "start_time": "2019-08-20T22:30:05.080126Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i,r in enumerate(detected):\n",
    "    visualize.display_instances(images[i], r['rois'], r['masks'], r['class_ids'], omni_class_set['LabelDescription'].values, r['scores'], show_mask=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T18:43:13.171293Z",
     "start_time": "2019-08-21T18:40:54.986588Z"
    }
   },
   "outputs": [],
   "source": [
    "anns = st.load_annotations_by_image()\n",
    "\n",
    "#down select to our validation data\n",
    "val_anns = anns[anns['RelativePath'].str.contains('validation',regex=False)]\n",
    "\n",
    "#get rid of the old labelId\n",
    "val_anns.drop(columns='LabelID',inplace=True)\n",
    "\n",
    "# join with tmp_set_classes on LabelName to get updated LabelID\n",
    "anns_by_image = pd.merge(val_anns,omni_class_set, on='LabelName',how='inner')\n",
    "\n",
    "anns_grouped = anns_by_image.groupby('ImageID')\n",
    "\n",
    "# validation dataset\n",
    "dataset = st.FullKaggleImageDataset()\n",
    "dataset.add_classes(omni_class_set.iloc[1:])  # do not add first background\n",
    "dataset.load_kaggle_images(DATA_DIR, anns_grouped)\n",
    "dataset.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visually validate dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T18:43:15.191075Z",
     "start_time": "2019-08-21T18:43:13.173722Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load and display random samples ... sanity check for data load\n",
    "image_ids = np.random.choice(dataset.image_ids, 5)\n",
    "for image_id in image_ids:\n",
    "    image = dataset.load_image(image_id)\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T19:30:03.977924Z",
     "start_time": "2019-08-21T19:29:58.994673Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_mAP(models, config, batch_size=2, sample_size=50):\n",
    "    \n",
    "    assert sample_size%batch_size == 0, 'Sample size must be divisible by batch_size'\n",
    "\n",
    "    image_ids = np.random.choice(dataset.image_ids, sample_size)\n",
    "\n",
    "    #each input is a tuple of form : image, image_meta, gt_class_id, gt_bbox, gt_mask\n",
    "    inputs = [modellib.load_image_gt(dataset, config, iid, use_mini_mask=False) for iid in image_ids]\n",
    "\n",
    "    APs = []\n",
    "\n",
    "    results = ensemble_detect(models, [inp[0] for inp in inputs],images_per_gpu, id_offsets)\n",
    "\n",
    "    for j in range(len(results)):\n",
    "        r = results[j]\n",
    "        # Compute AP\n",
    "        AP, precisions, recalls, overlaps = utils.compute_ap(inputs[j][3], inputs[j][2], inputs[j][4], \n",
    "                                            r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "        APs.append(AP)\n",
    "\n",
    "    return np.mean(APs)\n",
    "\n",
    "\n",
    "\n",
    "class KaggleConfig(TrainConfig):\n",
    "    NUM_CLASSES = len(omni_class_set)\n",
    "    \n",
    "class InferenceConfig(KaggleConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = images_per_gpu \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T19:58:17.372030Z",
     "start_time": "2019-08-27T19:57:01.951021Z"
    }
   },
   "outputs": [],
   "source": [
    "calc_mAP(models, InferenceConfig(),sample_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate kaggle submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference on 'test' set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T20:48:25.214439Z",
     "start_time": "2019-08-21T20:47:45.600770Z"
    }
   },
   "outputs": [],
   "source": [
    "config = InferenceConfig()\n",
    "batch_size=2\n",
    "\n",
    "#### Start code for sample ... real file should include entire test set ####\n",
    "sample_size=50 #todo this shouldn't be used, should be all of the training data\n",
    "    \n",
    "assert sample_size%batch_size == 0, 'Sample size must be divisible by batch_size'\n",
    "\n",
    "image_ids = np.random.choice(dataset.image_ids, sample_size)\n",
    "\n",
    "#each input is a tuple of form : image, image_meta, gt_class_id, gt_bbox, gt_mask\n",
    "inputs = [modellib.load_image_gt(dataset, config, iid, use_mini_mask=False) for iid in image_ids]\n",
    "\n",
    "images = [inp[0] for inp in inputs]\n",
    "\n",
    "#### End code for sample ... real file should include entire test set ####\n",
    "\n",
    "\n",
    "results = ensemble_detect(models, images,batch_size, id_offsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Kaggle Submission File from results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T19:50:44.473263Z",
     "start_time": "2019-08-27T19:50:44.383498Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO This cell will probably fail in the future as it assumes that \n",
    "# the body of the calculate_mAP function was executed outside of a function so that the\n",
    "# results and image_ids variables are exposed\n",
    "\n",
    "img_ids = anns_grouped.sum().index.values\n",
    "\n",
    "all_preds = []\n",
    "\n",
    "for j, r in enumerate(results):\n",
    "    preds = []\n",
    "    ids = r['class_ids']\n",
    "    boxes = r['rois']\n",
    "    scores = r['scores']\n",
    "    \n",
    "    preds = ''\n",
    "    \n",
    "    for i in range(len(r['class_ids'])):\n",
    "        preds += \" \" + \" \".join(map(str,[omni_class_set.iloc[ids[i]]['LabelName'], scores[i], boxes[i][1],boxes[i][0],boxes[i][3],boxes[i][2]]))\n",
    "    \n",
    "    iid = image_ids[j]  # this assumes that image_ids \n",
    "    \n",
    "    all_preds.append(img_ids[iid] + \", \" + preds[1:])\n",
    "\n",
    "#TODO grab from image_ids (based on index list) to get image name\n",
    "all_preds\n",
    "\n",
    "#TODO write to csv file\n",
    "with open(os.path.join(ROOT_DIR, 'submission.txt'), 'w') as f: \n",
    "    f.write('\\n'.join(all_preds)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Visualize results for individual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import skimage\n",
    "\n",
    "# test on a few random images\n",
    "# image_ids = np.random.choice(dataset_val.image_ids, inference_config.BATCH_SIZE)\n",
    "\n",
    "# images = [skimage.io.imread(os.path.join(DATA_DIR, rel_path)) for rel_path in ]\n",
    "\n",
    "#TODO should store image id in result as well ... this is just a quick hack\n",
    "\n",
    "img = skimage.io.imread(os.path.join(DATA_DIR, 'train/2fef4dd2f83feb18.jpg'))\n",
    "img2 = skimage.io.imread(os.path.join(DATA_DIR, 'train/55dee1384cd565ee.jpg'))\n",
    "\n",
    "images = [img,img2]\n",
    "\n",
    "#To store each models result for each image\n",
    "all_results = [[] for x in images]\n",
    "\n",
    "model_paths = ['kaggle20190815T2120/mask_rcnn_kaggle_0025.h5','kaggle20190815T2229/mask_rcnn_kaggle_0025.h5',\n",
    "               'kaggle20190815T2347/mask_rcnn_kaggle_0025.h5','kaggle20190816T0115/mask_rcnn_kaggle_0025.h5',\n",
    "               'kaggle20190816T0256/mask_rcnn_kaggle_0025.h5','kaggle20190816T0441/mask_rcnn_kaggle_0100.h5']\n",
    "\n",
    "\n",
    "models = load_member_models(model_paths, class_sets)\n",
    "\n",
    "\n",
    "for midx,model in enumerate(models):\n",
    "\n",
    "    results = model.detect(images, verbose=0)\n",
    "    \n",
    "    for i in range(len(results)):\n",
    "        r = results[i]\n",
    "        \n",
    "        r['model_id'] = midx\n",
    "        r['class_ids'] += id_offsets[midx]\n",
    "        \n",
    "        all_results[i].append(r)\n",
    "        \n",
    "        visualize.display_instances(images[i], r['rois'], r['masks'], r['class_ids'], omni_class_set['LabelDescription'].values, r['scores'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "328px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
