{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-16T16:43:54.431683Z",
     "start_time": "2019-09-16T16:43:50.590651Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import skimage\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "from openimages2019 import setup as st\n",
    "from openimages2019 import utils as u\n",
    "\n",
    "from skimage.draw import rectangle\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"../data\")\n",
    "\n",
    "#Make only 1 GPU visible\n",
    "!export HIP_VISIBLE_DEVICES=0\n",
    "\n",
    "#Set which GPU devices' memory should be accessible to running GPUs\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "\n",
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition the classes according to frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T21:22:41.750217Z",
     "start_time": "2019-09-09T21:21:06.883086Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_sets = st.partition_classes()\n",
    "\n",
    "\n",
    "def class_set_of(label_desc=None, label_name=None):\n",
    "    \"\"\"\n",
    "    Determine which class set the label name or label description falls under.  -1 returned if object is \n",
    "    not present in any class set\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    if label_name:\n",
    "        for i,cs in enumerate(class_sets):\n",
    "            if not cs[cs['LabelName'] == label_name].empty:\n",
    "                return i\n",
    "        \n",
    "    elif label_desc:\n",
    "        for i,cs in enumerate(class_sets):\n",
    "            if not cs[cs['LabelDescription'] == label_desc].empty:\n",
    "                return i\n",
    "        \n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T18:09:16.698117Z",
     "start_time": "2019-09-09T18:09:16.683531Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TrainConfig(Config):\n",
    "    \n",
    "    NAME = \"kaggle\"\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    \n",
    "    \n",
    "def get_infer_model(config, model_path=None):\n",
    "    inf_model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=MODEL_DIR)\n",
    "\n",
    "    if model_path is None:\n",
    "        model_path = inf_model.find_last()\n",
    "        \n",
    "    inf_model.load_weights(model_path, by_name=True)\n",
    "    \n",
    "    return inf_model\n",
    "\n",
    "\n",
    "def load_member_models(model_paths, class_sets, images_per_gpu=1):\n",
    "    models = []\n",
    "\n",
    "    for i,mpath in enumerate(model_paths):\n",
    "    \n",
    "        class InferenceConfig(TrainConfig):\n",
    "            NUM_CLASSES = len(class_sets[i])+ 1 # + 1 for background class\n",
    "            DETECTION_MIN_CONFIDENCE = 0.75\n",
    "\n",
    "        inf_config = InferenceConfig()\n",
    "\n",
    "        print(\"loading model: \", mpath )\n",
    "        model = get_infer_model(inf_config,model_path=mpath)\n",
    "        \n",
    "        models.append(model)\n",
    "        \n",
    "    return models\n",
    "\n",
    "\n",
    "def assemble(ind_results, iou_threshold=0.5):\n",
    "    \"\"\" Combines the results from many different models across a single images.  Uses NMS to handle overlaps\"\"\"\n",
    "\n",
    "    classes = np.concatenate([x['class_ids'] for x in ind_results])\n",
    "    scores = np.concatenate([x['scores'] for x in ind_results])\n",
    "\n",
    "    rois = np.concatenate([x['rois'] for x in ind_results],axis = 0)\n",
    "\n",
    "    #TODO just to display stuff ... not needed here\n",
    "    masks = np.concatenate([x['masks'] for x in ind_results],axis = 2)\n",
    "\n",
    "    if len(scores) > 0:\n",
    "        to_keep = range(len(scores)) #don't use NMS\n",
    "#         to_keep = utils.non_max_suppression(rois, scores, iou_threshold)\n",
    "        rval = {'class_ids' : classes[to_keep], 'rois' : rois[to_keep],\n",
    "            'scores' : scores[to_keep], 'masks' : masks[:,:,to_keep]}\n",
    "    else:\n",
    "        rval = {'class_ids' : [], 'rois' : [], 'scores' : [], 'masks' : []}\n",
    "#         Should make these empty np.arrays ... maybe?\n",
    "\n",
    "    return rval\n",
    "\n",
    "\n",
    "def ensemble_detect(models, images, batch_size, id_offsets):\n",
    "    \"\"\"\n",
    "    \n",
    "    For each model, run inference on image batches.  Then groups inference results by image and \n",
    "    applys non maximum suppression (via assemble method) to each group.\n",
    "    \n",
    "    \"\"\"\n",
    "    all_results = [[] for x in images]\n",
    "\n",
    "    for midx,model in enumerate(models):\n",
    "\n",
    "        results = []\n",
    "        \n",
    "        # Have to do this because of model.detect batch size assertion\n",
    "        for j in range(0,len(images),batch_size):\n",
    "            results += model.detect(images[j:j+batch_size], verbose=0)\n",
    "\n",
    "        for i in range(len(results)):\n",
    "            r = results[i]\n",
    "\n",
    "            r['model_id'] = midx\n",
    "            r['class_ids'] += id_offsets[midx]\n",
    "\n",
    "            all_results[i].append(r)\n",
    "            \n",
    "    return [assemble(x) for x in all_results]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Member model label ids --> ensemble model label ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T21:37:56.193196Z",
     "start_time": "2019-09-09T21:37:56.178503Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "background = ['/mnull','Background']\n",
    "    \n",
    "z = [np.insert(cset[['LabelName','LabelDescription']].values,0,background,axis=0) for cset in class_sets]\n",
    "\n",
    "omni_class_set = pd.DataFrame(np.concatenate(z),columns=['LabelName','LabelDescription'])\n",
    "omni_class_set['LabelID'] = omni_class_set.index\n",
    "\n",
    "id_offsets = omni_class_set[omni_class_set['LabelName'] == '/mnull'].index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T21:25:55.627718Z",
     "start_time": "2019-09-09T21:24:02.934150Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_paths = [os.path.join(DATA_DIR,'models','cset_' + str(i) + '_model.h5') for i in range(6)]\n",
    "\n",
    "models = load_member_models(model_paths, class_sets)\n",
    "\n",
    "\n",
    "##### GET RID OF FIRST MODEL #########\n",
    "# if (len(class_sets) == 6):\n",
    "#     class_sets = class_sets[1:]\n",
    "\n",
    "# models = load_member_models(model_paths[1:], class_sets)\n",
    "##!## NEED TO RERUN id_offsets cell above !!!!!!!\n",
    "\n",
    "##### END GET RID OF FIRST MODEL #########\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Simple demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Run inference on tiny set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T16:57:37.639053Z",
     "start_time": "2019-08-28T16:57:11.305082Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = skimage.io.imread(os.path.join(DATA_DIR, 'train/2fef4dd2f83feb18.jpg'))\n",
    "img2 = skimage.io.imread(os.path.join(DATA_DIR, 'train/55dee1384cd565ee.jpg'))\n",
    "\n",
    "images = [img,img2]\n",
    "\n",
    "detected = ensemble_detect(models, images,2, id_offsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T16:58:48.806717Z",
     "start_time": "2019-08-28T16:58:46.418068Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,r in enumerate(detected):\n",
    "    visualize.display_instances(images[i], r['rois'], r['masks'], r['class_ids'], omni_class_set['LabelDescription'].values, r['scores'], show_mask=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T21:39:45.929684Z",
     "start_time": "2019-09-09T21:38:07.479347Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anns = st.load_annotations_by_image()\n",
    "\n",
    "#down select to our validation data\n",
    "val_anns = anns[anns['RelativePath'].str.contains('validation',regex=False)]\n",
    "\n",
    "#get rid of the old labelId\n",
    "val_anns.drop(columns='LabelID',inplace=True)\n",
    "\n",
    "# join with tmp_set_classes on LabelName to get updated LabelID\n",
    "anns_by_image = pd.merge(val_anns,omni_class_set, on='LabelName',how='inner')\n",
    "\n",
    "anns_grouped = anns_by_image.groupby('ImageID')\n",
    "\n",
    "# validation dataset\n",
    "dataset = st.FullKaggleImageDataset()\n",
    "dataset.add_classes(omni_class_set.iloc[1:])  # do not add first background\n",
    "dataset.load_kaggle_images(DATA_DIR, anns_grouped)\n",
    "dataset.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Visually validate dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T18:43:15.191075Z",
     "start_time": "2019-08-21T18:43:13.173722Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load and display random samples ... sanity check for data load\n",
    "image_ids = np.random.choice(dataset.image_ids, 5)\n",
    "for image_id in image_ids:\n",
    "    image = dataset.load_image(image_id)\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T21:50:37.506910Z",
     "start_time": "2019-09-09T21:50:37.498635Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_mAP(models, config, batch_size=1, sample_size=50):\n",
    "    \n",
    "    assert sample_size%batch_size == 0, 'Sample size must be divisible by batch_size'\n",
    "\n",
    "    image_ids = np.random.choice(dataset.image_ids, sample_size)\n",
    "\n",
    "    #each input is a tuple of form : image, image_meta, gt_class_id, gt_bbox, gt_mask\n",
    "    inputs = [modellib.load_image_gt(dataset, config, iid, use_mini_mask=False) for iid in image_ids]\n",
    "\n",
    "    APs = []\n",
    "\n",
    "    results = ensemble_detect(models, [inp[0] for inp in inputs],batch_size, id_offsets)\n",
    "\n",
    "    for j in range(len(results)):\n",
    "        r = results[j]\n",
    "        # Compute AP\n",
    "        \n",
    "        if len(r[\"rois\"]) > 0: # function has bug, errors when nothing is found in an image ... so we ignore those for now\n",
    "            AP, precisions, recalls, overlaps = utils.compute_ap(inputs[j][3], inputs[j][2], inputs[j][4], \n",
    "                                                r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "            APs.append(AP)\n",
    "\n",
    "    return np.mean(APs)\n",
    "\n",
    "\n",
    "\n",
    "class KaggleConfig(TrainConfig):\n",
    "    NUM_CLASSES = len(omni_class_set)\n",
    "    \n",
    "class InferenceConfig(KaggleConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T21:54:10.614056Z",
     "start_time": "2019-09-09T21:50:39.791948Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calc_mAP(models, InferenceConfig(),sample_size=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Visualize some validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = InferenceConfig()\n",
    "batch_size=2\n",
    "\n",
    "#### Start code for sample ... real file should include entire test set ####\n",
    "sample_size=50 #todo this shouldn't be used, should be all of the training data\n",
    "    \n",
    "assert sample_size%batch_size == 0, 'Sample size must be divisible by batch_size'\n",
    "\n",
    "image_ids = np.random.choice(dataset.image_ids, sample_size)\n",
    "\n",
    "#each input is a tuple of form : image, image_meta, gt_class_id, gt_bbox, gt_mask\n",
    "inputs = [modellib.load_image_gt(dataset, config, iid, use_mini_mask=False) for iid in image_ids]\n",
    "\n",
    "images = [inp[0] for inp in inputs]\n",
    "\n",
    "#### End code for sample ... real file should include entire test set ####\n",
    "\n",
    "\n",
    "results = ensemble_detect(models, images,batch_size, id_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "\n",
    "for i,r in enumerate(results):\n",
    "    visualize.display_instances(images[i], r['rois'], r['masks'], r['class_ids'], omni_class_set['LabelDescription'].values, r['scores'], show_mask=False)\n",
    "    \n",
    "    cnt += 1\n",
    "    \n",
    "    if cnt > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate kaggle submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference on test set, batched writes (latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T16:44:04.104132Z",
     "start_time": "2019-09-09T16:44:04.088989Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "import os\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "#TODO image_info should be 2d array, with each row of form id, width, height\n",
    "def append_to_file(filename, results, image_info):\n",
    "    \n",
    "    all_preds = []\n",
    "    \n",
    "    for j, r in enumerate(results):\n",
    "        preds = []\n",
    "        ids = r['class_ids']\n",
    "        boxes = r['rois']\n",
    "        scores = r['scores']\n",
    "\n",
    "        img_id = image_info[j][0]\n",
    "        height = image_info[j][2]\n",
    "        width = image_info[j][1]\n",
    "        \n",
    "        preds = ''\n",
    "\n",
    "        for i in range(len(r['class_ids'])):\n",
    "            xmin = max(boxes[i][1] / width , 0.0)\n",
    "            ymin = max(boxes[i][0] / height, 0.0)\n",
    "            xmax = min(boxes[i][3] / width, 1.0)\n",
    "            ymax = min(boxes[i][2] / height, 1.0)\n",
    "            \n",
    "            preds += \" \" + \" \".join(map(str,[omni_class_set.iloc[ids[i]]['LabelName'], scores[i], xmin,ymin,xmax,ymax]))\n",
    "\n",
    "        all_preds.append(img_id + \",\" + preds)\n",
    "        \n",
    "    with open(filename, 'a') as f: \n",
    "        f.write('\\n'.join(all_preds))\n",
    "        f.write('\\n')\n",
    "    \n",
    "    \n",
    "\n",
    "testdir = os.path.join(DATA_DIR, \"test\")\n",
    "batch_size = 500\n",
    "\n",
    "\n",
    "def write_sub_file(filename, start_index=0):\n",
    "    results = []\n",
    "    image_info = []\n",
    "\n",
    "\n",
    "    for subdir, dirs, files in os.walk(testdir):\n",
    "        for cnt,file in enumerate(files):\n",
    "\n",
    "            #use this if the process broke down at some point and you need to restart midway through ... total hack\n",
    "            if cnt < start_index:\n",
    "                continue\n",
    "\n",
    "            img = skimage.io.imread(os.path.join(subdir, file))\n",
    "\n",
    "            #filename, width, height\n",
    "            image_info.append([file[:-4],img.shape[1],img.shape[0]])\n",
    "\n",
    "            results += ensemble_detect(models, [img],1, id_offsets)\n",
    "\n",
    "            if (cnt%batch_size == (batch_size-1)):\n",
    "                print(\"writing to file ... \")\n",
    "                append_to_file(filename, results,image_info)\n",
    "                results = []\n",
    "                image_info = []\n",
    "                print(cnt,\" completed\") #100,000 images in the test set\n",
    "                \n",
    "    print(\"writing final records to file ... \")\n",
    "    append_to_file(filename, results,image_info)\n",
    "    print(cnt,\" completed\")\n",
    "    \n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start the process from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-06T21:54:00.093Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOU ONLY WANT THIS IN PLACE FOR THE FIRST RUN ... afterwards it will wipe the file ... NOT GOOD !!!  \n",
    "\n",
    "filename = os.path.join(ROOT_DIR, 'submission9_11.csv')\n",
    "\n",
    "with open(filename, 'w+') as f:\n",
    "    f.write('ImageId,PredictionString\\n')\n",
    "    \n",
    "write_sub_file(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resume work at some file number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T16:58:49.107325Z",
     "start_time": "2019-09-09T16:47:57.536052Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write_sub_file(filename, start_index=99500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-16T16:44:44.776585Z",
     "start_time": "2019-09-16T16:44:44.247576Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(ROOT_DIR, 'submission9_11.csv'))\n",
    "\n",
    "# nu = df['ImageId'].nunique()  # Should be 99999\n",
    "\n",
    "# if len(df) > nu:\n",
    "#     df.drop_duplicates('ImageId', inplace = True)\n",
    "\n",
    "# df.to_csv('submission_9_11_0.csv',index=False)\n",
    "df.iloc[0]['PredictionString']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Run inference on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "testdir = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for subdir, dirs, files in os.walk(testdir):\n",
    "    for i,file in enumerate(files):\n",
    "        results += ensemble_detect(models, [skimage.io.imread(os.path.join(subdir, file))],1, id_offsets)\n",
    "        \n",
    "        if (i%10 == 0):\n",
    "            print(i/1000) #100,000 images in the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T18:50:25.142754Z",
     "start_time": "2019-08-28T18:50:19.987024Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TO USE THIS:\n",
    "# You need to store the images above instead of loading them as a function argument\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for i,r in enumerate(results):\n",
    "    visualize.display_instances(images[i], r['rois'], r['masks'], r['class_ids'], omni_class_set['LabelDescription'].values, r['scores'], show_mask=False)\n",
    "    \n",
    "    cnt += 1\n",
    "    \n",
    "    if cnt > 5:\n",
    "        break   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Kaggle Submission File from results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-01T19:33:10.644Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO This cell will probably fail in the future as it assumes that \n",
    "# the body of the calculate_mAP function was executed outside of a function so that the\n",
    "# results and image_ids variables are exposed\n",
    "\n",
    "img_ids = anns_grouped.sum().index.values\n",
    "\n",
    "all_preds = []\n",
    "\n",
    "#DONT KNOW ABOUT ORDERING ANYMORE ...\n",
    "for j, r in enumerate(results):\n",
    "    preds = []\n",
    "    ids = r['class_ids']\n",
    "    boxes = r['rois']\n",
    "    scores = r['scores']\n",
    "    \n",
    "    preds = ''\n",
    "    \n",
    "    for i in range(len(r['class_ids'])):\n",
    "        preds += \" \" + \" \".join(map(str,[omni_class_set.iloc[ids[i]]['LabelName'], scores[i], boxes[i][1],boxes[i][0],boxes[i][3],boxes[i][2]]))\n",
    "    \n",
    "    iid = image_ids[j]\n",
    "    \n",
    "    all_preds.append(img_ids[iid] + \", \" + preds[1:])\n",
    "\n",
    "\n",
    "#TODO write to csv file\n",
    "with open(os.path.join(ROOT_DIR, 'submission.csv'), 'w') as f: \n",
    "    f.write('ImageId,PredictionString\\n')\n",
    "    f.write('\\n'.join(all_preds)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T22:14:00.853714Z",
     "start_time": "2019-09-09T22:14:00.850375Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class InferenceConfig(TrainConfig):\n",
    "    NUM_CLASSES = len(omni_class_set) # + 1 for background class\n",
    "\n",
    "inf_config = InferenceConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T22:14:05.293378Z",
     "start_time": "2019-09-09T22:14:02.374176Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# random images\n",
    "image_ids = np.random.choice(dataset.image_ids, 30)\n",
    "\n",
    "\n",
    "\n",
    "# single object scenes\n",
    "# image_ids = [28542,16831,26167,1290,1694]\n",
    "\n",
    "# single object with parts scenes\n",
    "# image_ids = [16020,31270,16615,16364,29407,12841,19720]\n",
    "\n",
    "#more complicated scenes\n",
    "# image_ids = [6596,14954,6081,28724,9376]\n",
    "\n",
    "#complicated scenes\n",
    "# image_ids = [30670, 4918,13704,15065,22429,8799]\n",
    "\n",
    "ver_images = []\n",
    "\n",
    "for iid in image_ids:\n",
    "    original_image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset, inf_config, iid, use_mini_mask=False)\n",
    "\n",
    "    #UNCOMMENT THESE LINES TO VISUALIZE\n",
    "#     print(iid)\n",
    "#     visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "#                             dataset.class_names, figsize=(8, 8))\n",
    "    \n",
    "    ver_images.append(original_image)\n",
    "    \n",
    "# [30670, 4918, 6596, 13792]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T22:14:08.945734Z",
     "start_time": "2019-09-09T22:14:08.934255Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_em(image,iid,mode='all'):\n",
    "\n",
    "    if mode == 'all' :\n",
    "        for midx,model in enumerate(models):\n",
    "            results = model.detect([image], verbose=0)\n",
    "\n",
    "            for i in range(len(results)):\n",
    "                r = results[i]\n",
    "\n",
    "                r['model_id'] = midx\n",
    "                r['class_ids'] += id_offsets[midx]\n",
    "\n",
    "\n",
    "                visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], omni_class_set['LabelDescription'].values, r['scores'])\n",
    "\n",
    "    print(\"----------------- ENSEMBLE ---------------------\")\n",
    "    eresults = ensemble_detect(models, [image],batch_size, id_offsets)\n",
    "    r = eresults[0]\n",
    "    \n",
    "    visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], omni_class_set['LabelDescription'].values,\n",
    "                                r['scores'], show_mask=False,figsize=(10, 10))\n",
    "\n",
    "\n",
    "    print(\"----------------- Ground Truth ---------------------\")\n",
    "    inf_config = InferenceConfig()\n",
    "    original_image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset, inf_config, iid, use_mini_mask=False)\n",
    "\n",
    "    # visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "    #                             dataset.class_names, figsize=(8, 8))\n",
    "    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                                dataset.class_names,show_mask=False,figsize=(10, 10))\n",
    "\n",
    "\n",
    "    AP, precisions, recalls, overlaps = utils.compute_ap(gt_bbox, gt_class_id, gt_mask, \n",
    "                                                 r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "\n",
    "    print(\"Average Precision: \", AP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T22:14:59.056744Z",
     "start_time": "2019-09-09T22:14:10.838740Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "for i in range(30):\n",
    "    visualize_em(ver_images[i],image_ids[i],mode='ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T20:59:51.449041Z",
     "start_time": "2019-09-09T20:59:51.439668Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for x in ['Porch','Car', 'Fountain', 'Goose', 'Bird','Scissors','Sports uniform', 'Fox']:\n",
    "#     print(x, class_set_of(x))\n",
    "    \n",
    "class_sets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T19:02:17.779050Z",
     "start_time": "2019-09-06T19:02:17.768816Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "omni_class_set[omni_class_set['LabelID'].isin([161,416,490,502])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Ad hoc visualization code (moved to visualize_em function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import skimage\n",
    "\n",
    "# img = skimage.io.imread(os.path.join(DATA_DIR, 'train/2fef4dd2f83feb18.jpg'))\n",
    "# img2 = skimage.io.imread(os.path.join(DATA_DIR, 'train/55dee1384cd565ee.jpg'))\n",
    "\n",
    "\n",
    "####   Use Images defined above   ####\n",
    "# images = [img]\n",
    "\n",
    "a = 1\n",
    "iid = image_ids[a]\n",
    "images = ver_images[a:(a+1)]\n",
    "\n",
    "#To store each models result for each image\n",
    "all_results = [[] for x in images]\n",
    "\n",
    "\n",
    "for midx,model in enumerate(models):\n",
    "    results = model.detect(images, verbose=0)\n",
    "    \n",
    "    for i in range(len(results)):\n",
    "        r = results[i]\n",
    "        \n",
    "        r['model_id'] = midx\n",
    "        r['class_ids'] += id_offsets[midx]\n",
    "        \n",
    "        all_results[i].append(r)\n",
    "        \n",
    "        visualize.display_instances(images[i], r['rois'], r['masks'], r['class_ids'], omni_class_set['LabelDescription'].values, r['scores'])\n",
    "\n",
    "print(\"ENSEMBLE\")\n",
    "eresults = ensemble_detect(models, images,batch_size, id_offsets)\n",
    "r = eresults[0]\n",
    "visualize.display_instances(images[0], r['rois'], r['masks'], r['class_ids'], omni_class_set['LabelDescription'].values, r['scores'], show_mask=False)\n",
    "\n",
    "\n",
    "print(\"Ground Truth\")\n",
    "inf_config = InferenceConfig()\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset, inf_config, iid, use_mini_mask=False)\n",
    "\n",
    "# visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "#                             dataset.class_names, figsize=(8, 8))\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset.class_names,show_mask=False)\n",
    "\n",
    "\n",
    "AP, precisions, recalls, overlaps = utils.compute_ap(gt_bbox, gt_class_id, gt_mask, \n",
    "                                                r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "\n",
    "print(\"Average Precision: \", AP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate mAP for member models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T16:59:56.482358Z",
     "start_time": "2019-09-09T16:59:56.476525Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eval_single_model(model_path,cset_index=None, mAP_sample_size=250,class_set=None,val_data=None):\n",
    "\n",
    "    if class_set is None:\n",
    "        class_set = class_sets[cset_index]\n",
    "        \n",
    "    if val_data is None:\n",
    "        anns = st.load_annotations_by_image(class_set)    \n",
    "        val_data = st.load_dataset(anns, DATA_DIR, class_set, is_train=False)\n",
    "\n",
    "    class KaggleConfig(TrainConfig):\n",
    "        NUM_CLASSES = len(class_set) + 1 # + 1 for background class\n",
    "\n",
    "    inf_config = KaggleConfig()\n",
    "    \n",
    "    inf_model = modellib.MaskRCNN(mode=\"inference\", config=inf_config, model_dir=MODEL_DIR)\n",
    "\n",
    "    inf_model.load_weights(model_path, by_name=True)\n",
    "    \n",
    "    return u.eval_mAP(inf_model, val_data, inf_config, mAP_sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single model using recently trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Single evaluation for a single model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_single_model(os.path.join(MODEL_DIR,'kaggle20190903T1053',\"mask_rcnn_kaggle_0165.h5\"),cset_index=2, mAP_sample_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple evaluations of a single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T17:03:10.563411Z",
     "start_time": "2019-09-09T17:01:49.708298Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build the validation data set once for faster mAP evaluation\n",
    "\n",
    "cset_index = 2\n",
    "\n",
    "class_set = class_sets[cset_index]\n",
    "        \n",
    "anns = st.load_annotations_by_image(class_set)    \n",
    "val_data = st.load_dataset(anns, DATA_DIR, class_set, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T17:07:33.870074Z",
     "start_time": "2019-09-09T17:04:09.252680Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(148,151):\n",
    "    print(i,eval_single_model(os.path.join(MODEL_DIR,'kaggle20190906T1449',\"mask_rcnn_kaggle_0\" + str(i) + \".h5\"),\n",
    "                  class_set=class_set, val_data=val_data, mAP_sample_size=250))\n",
    "\n",
    "# eval_single_model(os.path.join(MODEL_DIR,'kaggle20190903T1053',\"mask_rcnn_kaggle_0165.h5\"),\n",
    "#                   class_set=class_set, val_data=val_data, mAP_sample_size=250)\n",
    "    \n",
    "# copy recently trained model to models directory\n",
    "\n",
    "#model from epoch 164 had mAP of 0.189, val_loss of 2.00\n",
    "#model from epoch 165 had mAP of 0.271, val_loss of 1.322\n",
    "#model from epoch 166 had mAP of 0.29, val_loss of 1.551\n",
    "#model from epoch 74, had mAP of 0.201, val_loss of 4.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### All models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Load models (duplicates cell from above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_paths = [os.path.join(DATA_DIR,'models','cset_' + str(i) + '_model.h5') for i in range(6)]\n",
    "\n",
    "models = load_member_models(model_paths, class_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Run all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T17:10:25.771066Z",
     "start_time": "2019-09-03T16:55:54.646866Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,mpath in enumerate(model_paths):\n",
    "    print(i, eval_single_model(mpath,cset_index=i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "328px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
