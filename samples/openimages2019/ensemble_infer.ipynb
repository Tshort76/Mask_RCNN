{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T14:57:35.877842Z",
     "start_time": "2019-09-30T14:57:32.882022Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import skimage\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "from openimages2019 import setup as st\n",
    "from openimages2019 import utils as u\n",
    "\n",
    "from skimage.draw import rectangle\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"../data\")\n",
    "\n",
    "MASK_DIR = os.path.join(DATA_DIR, \"segmentation\")\n",
    "\n",
    "##############################\n",
    "USE_MASKS = True\n",
    "##############################\n",
    "\n",
    "#Make only 1 GPU visible\n",
    "!export HIP_VISIBLE_DEVICES=0\n",
    "\n",
    "#Set which GPU devices' memory should be accessible to running GPUs\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "\n",
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Partition the classes according to frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T14:59:07.736037Z",
     "start_time": "2019-09-30T14:57:41.712294Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO update this to account for masks (USE_MASK)\n",
    "# class_sub_sets = st.partition_classes()\n",
    "\n",
    "if USE_MASKS:\n",
    "    all_classes = st.load_classes(path_to_csv=os.path.join(DATA_DIR,'seg_class_descriptions.csv'))\n",
    "    anns = st.load_annotations_by_image(classes=all_classes, use_masks=True)\n",
    "else:\n",
    "    all_classes = st.load_classes()\n",
    "    anns = st.load_annotations_by_image(classes=all_classes, use_masks=False)\n",
    "\n",
    "    \n",
    "cnts = anns['LabelName'].value_counts()\n",
    "\n",
    "class_sub_sets = []\n",
    "\n",
    "n_partitions = 10\n",
    "\n",
    "p_size = int(len(all_classes) / n_partitions)\n",
    "\n",
    "for i in range(n_partitions):\n",
    "    s = i*p_size\n",
    "    idxs = cnts.iloc[s:(s+p_size)].index.values\n",
    "    tmp_set = all_classes[all_classes['LabelName'].isin(idxs)]\n",
    "    tmp_set = tmp_set.reset_index()\n",
    "    tmp_set['LabelID'] = tmp_set.index + 1\n",
    "    class_sub_sets.append(tmp_set)\n",
    "\n",
    "\n",
    "\n",
    "def class_set_of(label_desc=None, label_name=None):\n",
    "    \"\"\"\n",
    "    Determine which class set the label name or label description falls under.  -1 returned if object is \n",
    "    not present in any class set\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    if label_name:\n",
    "        for i,cs in enumerate(class_sub_sets):\n",
    "            if not cs[cs['LabelName'] == label_name].empty:\n",
    "                return i\n",
    "        \n",
    "    elif label_desc:\n",
    "        for i,cs in enumerate(class_sub_sets):\n",
    "            if not cs[cs['LabelDescription'] == label_desc].empty:\n",
    "                return i\n",
    "        \n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:29:03.935760Z",
     "start_time": "2019-09-30T15:29:03.917933Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TrainConfig(Config):\n",
    "    \n",
    "    NAME = \"kaggle\"\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_NMS_THRESHOLD = 0.0\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    \n",
    "    \n",
    "def get_infer_model(config, model_path):\n",
    "    inf_model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=MODEL_DIR)\n",
    "        \n",
    "    inf_model.load_weights(model_path, by_name=True)\n",
    "    \n",
    "    return inf_model\n",
    "\n",
    "\n",
    "def load_member_models(model_paths, class_sets, images_per_gpu=1):\n",
    "    models = []\n",
    "\n",
    "    for i,mpath in enumerate(model_paths):\n",
    "    \n",
    "        class InferenceConfig(TrainConfig):\n",
    "            NUM_CLASSES = len(class_sets[i])+ 1 # + 1 for background class\n",
    "            DETECTION_MIN_CONFIDENCE = 0.9\n",
    "\n",
    "        inf_config = InferenceConfig()\n",
    "\n",
    "        print(\"loading model: \", mpath )\n",
    "        model = get_infer_model(inf_config,model_path=mpath)\n",
    "        \n",
    "        models.append(model)\n",
    "        \n",
    "    return models\n",
    "\n",
    "\n",
    "def assemble(ind_results, iou_threshold=0.3):\n",
    "    \"\"\" Combines the results from many different models across a single images.  Uses NMS to handle overlaps\"\"\"\n",
    "\n",
    "    classes = np.concatenate([x['class_ids'] for x in ind_results])\n",
    "    \n",
    "    scores = np.concatenate([x['scores'] for x in ind_results])\n",
    "\n",
    "    rois = np.concatenate([x['rois'] for x in ind_results],axis = 0)\n",
    "\n",
    "    masks = np.concatenate([x['masks'] for x in ind_results],axis = 2)\n",
    "\n",
    "    if len(scores) > 0:\n",
    "#         to_keep = range(len(scores)) #don't use NMS\n",
    "        to_keep = utils.non_max_suppression(rois, scores, iou_threshold)\n",
    "        rval = {'class_ids' : classes[to_keep], 'rois' : rois[to_keep],\n",
    "            'scores' : scores[to_keep], 'masks' : masks[:,:,to_keep]}\n",
    "    else:\n",
    "        rval = {'class_ids' : np.array([]), 'rois' : np.array([]), 'scores' : np.array([]), 'masks' : np.array([])}\n",
    "\n",
    "    return rval\n",
    "\n",
    "\n",
    "def assemble_hierarchy(ind_results, iou_threshold=0.3):\n",
    "    \"\"\" Combines the results from many different models across a single images.  Uses NMS to handle overlaps\"\"\"\n",
    "\n",
    "    classes = np.concatenate([x['class_ids'] for x in ind_results])\n",
    "    \n",
    "    # We assume that the last result is from a general model and prefer its outputs \n",
    "    ind_results[-1]['scores'] += 0.25\n",
    "    \n",
    "    scores = np.concatenate([x['scores'] for x in ind_results])\n",
    "\n",
    "    rois = np.concatenate([x['rois'] for x in ind_results],axis = 0)\n",
    "\n",
    "    masks = np.concatenate([x['masks'] for x in ind_results],axis = 2)\n",
    "\n",
    "    if len(scores) > 0:\n",
    "        to_keep = utils.non_max_suppression(rois, scores, iou_threshold)\n",
    "        rval = {'class_ids' : classes[to_keep], 'rois' : rois[to_keep],\n",
    "            'scores' : np.array([min(0.999,x) for x in scores[to_keep]]), 'masks' : masks[:,:,to_keep]}\n",
    "    else:\n",
    "        rval = {'class_ids' : np.array([]), 'rois' : np.array([]), 'scores' : np.array([]), 'masks' : np.array([])}\n",
    "\n",
    "    return rval\n",
    "\n",
    "\n",
    "#TODO should eventually pass in 2 sets of models, expert models and general models\n",
    "def ensemble_detect(models, images, id_conv_fn):\n",
    "    \"\"\"\n",
    "    \n",
    "    For each model, run inference on image batches.  Then groups inference results by image and \n",
    "    applys non maximum suppression (via assemble method) to each group.\n",
    "    \n",
    "    \"\"\"\n",
    "    all_results = [[] for x in images]\n",
    "\n",
    "    for midx,model in enumerate(models):\n",
    "\n",
    "        results = []\n",
    "        \n",
    "        for img in images:\n",
    "            results += model.detect([img], verbose=0)\n",
    "        \n",
    "        #HARD code batchsize of 4 ... for now\n",
    "#         for z in range(0,len(images),4):\n",
    "#             tmp = images[z:z+4]\n",
    "#             results += model.detect(tmp, verbose=0)\n",
    "\n",
    "        for i in range(len(results)):\n",
    "            r = results[i]\n",
    "\n",
    "            r['model_id'] = midx\n",
    "            r['class_ids'] = id_conv_fn[midx](r['class_ids'])\n",
    "\n",
    "            all_results[i].append(r)\n",
    "    \n",
    "#     return [assemble(x) for x in all_results]\n",
    "    return [assemble_hierarchy(x) for x in all_results]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Member model label ids --> ensemble model label ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:22:05.039220Z",
     "start_time": "2019-09-30T15:22:04.984175Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "background = ['/mnull','Background']\n",
    "    \n",
    "z = [np.insert(cset[['LabelName','LabelDescription']].values,0,background,axis=0) for cset in class_sub_sets]\n",
    "\n",
    "omni_class_set = pd.DataFrame(np.concatenate(z),columns=['LabelName','LabelDescription'])\n",
    "omni_class_set['LabelID'] = omni_class_set.index\n",
    "\n",
    "id_offsets = omni_class_set[omni_class_set['LabelName'] == '/mnull'].index.values\n",
    "\n",
    "\n",
    "## For the partitions, a simple offset will work to map from model id to ensemble id\n",
    "def simp_offset(offset):\n",
    "    return lambda cids : cids + offset\n",
    "\n",
    "offset_fns = [simp_offset(i) for i in id_offsets]\n",
    "\n",
    "#### map from all_classes labelid -> omni_class_set labelid\n",
    "mapping = all_classes.merge(omni_class_set, on='LabelName')[['LabelID_x','LabelID_y']]\n",
    "mapping_map = {r['LabelID_x'] : r['LabelID_y'] for _,r in mapping.iterrows()}\n",
    "tmp_fn = lambda x : mapping_map[x]\n",
    "conv_fn = lambda cids : np.array(list(map(tmp_fn,cids)))\n",
    "\n",
    "#subselect for now while testing\n",
    "id_mappings = offset_fns #[0:10]\n",
    "id_mappings.append(conv_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:33:30.244145Z",
     "start_time": "2019-09-30T15:29:14.021964Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_paths = [os.path.join(DATA_DIR,'models','cset_' + str(i) + '_model.h5') for i in range(6)]\n",
    "# models = load_member_models(model_paths, class_sub_sets)\n",
    "\n",
    "\n",
    "######## expert classifiers for 2 groups of classes plus 1 for the entire data set\n",
    "\n",
    "model_paths = [os.path.join(MODEL_DIR,'kaggle20190920T1549/mask_rcnn_kaggle_0038.h5'),\n",
    "               os.path.join(MODEL_DIR,'kaggle20190921T0133/mask_rcnn_kaggle_0046.h5'),\n",
    "               os.path.join(MODEL_DIR,'kaggle20190921T1014/mask_rcnn_kaggle_0045.h5'),\n",
    "               os.path.join(MODEL_DIR,'kaggle20190921T1813/mask_rcnn_kaggle_0048.h5'),\n",
    "               os.path.join(MODEL_DIR,'kaggle20190922T0153/mask_rcnn_kaggle_0042.h5'),\n",
    "               os.path.join(MODEL_DIR,'kaggle20190922T0930/mask_rcnn_kaggle_0049.h5'),\n",
    "               os.path.join(MODEL_DIR,'kaggle20190922T1704/mask_rcnn_kaggle_0045.h5'),\n",
    "               os.path.join(MODEL_DIR,'kaggle20190923T0040/mask_rcnn_kaggle_0035.h5'),\n",
    "               os.path.join(MODEL_DIR,'kaggle20190923T0821/mask_rcnn_kaggle_0025.h5'),\n",
    "               os.path.join(MODEL_DIR,'kaggle20190923T1532/mask_rcnn_kaggle_0054.h5'),\n",
    "               os.path.join(MODEL_DIR,'kaggle20190923T1355/mask_rcnn_kaggle_0822.h5')\n",
    "              ]\n",
    "\n",
    "\n",
    "class_groups = class_sub_sets #[0:10]\n",
    "class_groups.append(all_classes)\n",
    "\n",
    "models = load_member_models(model_paths, class_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Simple demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Run inference on tiny set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-21T18:46:04.201316Z",
     "start_time": "2019-09-21T18:45:44.757864Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = skimage.io.imread(os.path.join(DATA_DIR, 'train/2fef4dd2f83feb18.jpg'))\n",
    "img2 = skimage.io.imread(os.path.join(DATA_DIR, 'train/55dee1384cd565ee.jpg'))\n",
    "\n",
    "images = [img,img2]\n",
    "\n",
    "# detected = ensemble_detect(models, images,1, id_offsets)\n",
    "detected = ensemble_detect(models, images, id_mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-21T18:46:07.697247Z",
     "start_time": "2019-09-21T18:46:04.205339Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,r in enumerate(detected):\n",
    "    visualize.display_instances(images[i], r['rois'], r['masks'], r['class_ids'], omni_class_set['LabelDescription'].values, r['scores'], show_mask=USE_MASKS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Build the validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:27:34.089240Z",
     "start_time": "2019-09-30T15:26:50.166815Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "anns = st.load_annotations_by_image(use_masks=USE_MASKS)\n",
    "\n",
    "if USE_MASKS:\n",
    "    val_anns = anns[anns['SourceDataset'] == 'validation']\n",
    "else:\n",
    "    val_anns = anns[anns['RelativePath'].str.contains('validation',regex=False)]\n",
    "\n",
    "val_anns.drop(columns='LabelID',inplace=True)\n",
    "\n",
    "# join with tmp_set_classes on LabelName to get updated LabelID\n",
    "anns_by_image = pd.merge(val_anns,omni_class_set, on='LabelName',how='inner')\n",
    "\n",
    "anns_grouped = anns_by_image.groupby('ImageID')\n",
    "\n",
    "# validation dataset\n",
    "dataset = st.OpenImageDataset()\n",
    "dataset.add_classes(omni_class_set.iloc[1:])  #load all but background class, which gets added automatically\n",
    "\n",
    "if USE_MASKS:\n",
    "    dataset.set_mask_path(MASK_DIR)\n",
    "\n",
    "dataset.load_image_files(DATA_DIR, anns_grouped)\n",
    "dataset.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Visually validate dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T15:21:18.026940Z",
     "start_time": "2019-09-23T15:21:15.380679Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load and display random samples ... sanity check for data load\n",
    "image_ids = np.random.choice(dataset.image_ids, 5)\n",
    "for image_id in image_ids:\n",
    "    image = dataset.load_image(image_id)\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T21:43:17.177094Z",
     "start_time": "2019-09-30T21:43:17.165171Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_mAP(models, config, sample_size=250):\n",
    "    \n",
    "    image_ids = np.random.choice(dataset.image_ids, sample_size)\n",
    "\n",
    "    #each input is a tuple of form : image, image_meta, gt_class_id, gt_bbox, gt_mask\n",
    "    inputs = [modellib.load_image_gt(dataset, config, iid, use_mini_mask=False) for iid in image_ids]\n",
    "\n",
    "    APs = []\n",
    "\n",
    "    results = ensemble_detect(models, [inp[0] for inp in inputs], id_mappings)\n",
    "\n",
    "    for j in range(len(results)):\n",
    "        r = results[j]\n",
    "        # Compute AP\n",
    "        \n",
    "        if len(r[\"rois\"]) > 0: # function has bug, errors when nothing is found in an image ... so we ignore those for now\n",
    "            AP, precisions, recalls, overlaps = utils.compute_ap(inputs[j][3], inputs[j][2], inputs[j][4], \n",
    "                                                r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "            APs.append(AP)\n",
    "\n",
    "    return np.mean(APs)\n",
    "\n",
    "\n",
    "class KaggleConfig(TrainConfig):\n",
    "    NUM_CLASSES = len(omni_class_set)\n",
    "    \n",
    "class InferenceConfig(KaggleConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check acc threshold vs score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T22:13:17.647535Z",
     "start_time": "2019-09-30T22:02:12.608080Z"
    }
   },
   "outputs": [],
   "source": [
    "config = InferenceConfig()\n",
    "\n",
    "image_ids = np.random.choice(dataset.image_ids, 500)\n",
    "\n",
    "inputs = [modellib.load_image_gt(dataset, config, iid, use_mini_mask=False) for iid in image_ids]\n",
    "\n",
    "APs = []\n",
    "\n",
    "results = ensemble_detect(models, [inp[0] for inp in inputs], id_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T22:50:38.191240Z",
     "start_time": "2019-09-30T22:50:38.183701Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_mAP(acc_thresh):\n",
    "    for j in range(len(results)):\n",
    "        r = results[j]\n",
    "        \n",
    "        to_keep = np.where(r['scores'] >= acc_thresh)\n",
    "        z = {k : r[k][to_keep] for k in ['rois','class_ids','scores']}\n",
    "        \n",
    "        \n",
    "        if r['masks'].shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        z['masks'] = r['masks'][:,:,to_keep]\n",
    "        r=z\n",
    "        \n",
    "        if len(r[\"rois\"]) > 0: # function has bug, errors when nothing is found in an image ... so we ignore those for now\n",
    "            AP, precisions, recalls, overlaps = utils.compute_ap(inputs[j][3], inputs[j][2], inputs[j][4], \n",
    "                                                r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "            APs.append(AP)\n",
    "\n",
    "    return np.mean(APs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T22:53:13.559748Z",
     "start_time": "2019-09-30T22:50:59.920103Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(0.8, 1.0, 0.005)\n",
    "y = []\n",
    "\n",
    "for r in x:\n",
    "    try:\n",
    "        y.append(check_mAP(r))\n",
    "    except:\n",
    "        y.append(0.0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-30T22:53:17.064Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omni_df = pd.read_csv(os.path.join(ROOT_DIR, 'seg_omni_submission_9_29.csv'))\n",
    "ex_df = pd.read_csv(os.path.join(DATA_DIR, 'submissions/tlong/seg_submission_9_25.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#goal is to step over each row and remove any elements of the prediction string with an accuracy lower than our threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Run the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T21:43:27.586820Z",
     "start_time": "2019-09-30T21:43:24.796079Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calc_mAP(models, InferenceConfig(), sample_size=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Visualize some validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-21T18:27:46.134158Z",
     "start_time": "2019-09-21T18:27:05.710563Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = InferenceConfig()\n",
    "\n",
    "#### Start code for sample ... real file should include entire test set ####\n",
    "sample_size=50 #todo this shouldn't be used, should be all of the training data\n",
    "\n",
    "image_ids = np.random.choice(dataset.image_ids, sample_size)\n",
    "\n",
    "#each input is a tuple of form : image, image_meta, gt_class_id, gt_bbox, gt_mask\n",
    "inputs = [modellib.load_image_gt(dataset, config, iid, use_mini_mask=False) for iid in image_ids]\n",
    "\n",
    "images = [inp[0] for inp in inputs]\n",
    "\n",
    "#### End code for sample ... real file should include entire test set ####\n",
    "\n",
    "\n",
    "results = ensemble_detect(models, images, id_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-21T18:40:14.676793Z",
     "start_time": "2019-09-21T18:40:09.615600Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "\n",
    "for i,r in enumerate(results):\n",
    "    if(len(r['class_ids']) > 0):\n",
    "        visualize.display_instances(images[i], r['rois'], r['masks'], r['class_ids'], omni_class_set['LabelDescription'].values, r['scores'], show_mask=USE_MASKS)\n",
    "    \n",
    "        cnt += 1\n",
    "    \n",
    "    if cnt > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Generate kaggle submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Define functions for batch writing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T16:44:04.104132Z",
     "start_time": "2019-09-09T16:44:04.088989Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "import os\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "#TODO image_info should be 2d array, with each row of form id, width, height\n",
    "def append_to_file_det(filename, results, image_info):\n",
    "    \n",
    "    all_preds = []\n",
    "    \n",
    "    for j, r in enumerate(results):\n",
    "        preds = []\n",
    "        ids = r['class_ids']\n",
    "        boxes = r['rois']\n",
    "        scores = r['scores']\n",
    "\n",
    "        img_id = image_info[j][0]\n",
    "        height = image_info[j][2]\n",
    "        width = image_info[j][1]\n",
    "        \n",
    "        preds = ''\n",
    "\n",
    "        for i in range(len(r['class_ids'])):\n",
    "            xmin = max(boxes[i][1] / width , 0.0)\n",
    "            ymin = max(boxes[i][0] / height, 0.0)\n",
    "            xmax = min(boxes[i][3] / width, 1.0)\n",
    "            ymax = min(boxes[i][2] / height, 1.0)\n",
    "            \n",
    "            preds += \" \" + \" \".join(map(str,[omni_class_set.iloc[ids[i]]['LabelName'], scores[i], xmin,ymin,xmax,ymax]))\n",
    "\n",
    "        all_preds.append(img_id + \",\" + preds)\n",
    "        \n",
    "    with open(filename, 'a') as f: \n",
    "        f.write('\\n'.join(all_preds))\n",
    "        f.write('\\n')\n",
    "    \n",
    "    \n",
    "\n",
    "testdir = os.path.join(DATA_DIR, \"test\")\n",
    "batch_size = 500\n",
    "\n",
    "\n",
    "def write_sub_file_det(filename, start_index=0):\n",
    "    results = []\n",
    "    image_info = []\n",
    "\n",
    "\n",
    "    for subdir, dirs, files in os.walk(testdir):\n",
    "        for cnt,file in enumerate(files):\n",
    "\n",
    "            #use this if the process broke down at some point and you need to restart midway through ... total hack\n",
    "            if cnt < start_index:\n",
    "                continue\n",
    "\n",
    "            img = skimage.io.imread(os.path.join(subdir, file))\n",
    "\n",
    "            #filename, width, height\n",
    "            image_info.append([file[:-4],img.shape[1],img.shape[0]])\n",
    "\n",
    "            results += ensemble_detect(models, [img], id_mappings)\n",
    "\n",
    "            if (cnt%batch_size == (batch_size-1)):\n",
    "                print(\"writing to file ... \")\n",
    "                append_to_file_det(filename, results,image_info)\n",
    "                results = []\n",
    "                image_info = []\n",
    "                print(cnt,\" completed\") #100,000 images in the test set\n",
    "                \n",
    "    print(\"writing final records to file ... \")\n",
    "    append_to_file_det(filename, results,image_info)\n",
    "    print(cnt,\" completed\")\n",
    "    \n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Object Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T23:22:58.132773Z",
     "start_time": "2019-09-29T23:22:58.113415Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# container does not include this library by default, will need to run this once\n",
    "# !pip install pycocotools\n",
    "\n",
    "import base64\n",
    "from pycocotools import _mask as coco_mask\n",
    "import typing as t\n",
    "import zlib\n",
    "\n",
    "\n",
    "def encode_binary_mask(mask: np.ndarray):\n",
    "\n",
    "     # check input mask --\n",
    "    if mask.dtype != np.bool:\n",
    "        raise ValueError(\n",
    "           \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n",
    "           mask.dtype)\n",
    "\n",
    "    mask = np.squeeze(mask)\n",
    "    if len(mask.shape) != 2:\n",
    "        raise ValueError(\n",
    "           \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n",
    "           mask.shape)\n",
    "\n",
    "     # convert input mask to expected COCO API input --\n",
    "    mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
    "    mask_to_encode = mask_to_encode.astype(np.uint8)\n",
    "    mask_to_encode = np.asfortranarray(mask_to_encode)\n",
    "\n",
    "    # RLE encode mask --\n",
    "    encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n",
    "\n",
    "    # compress and base64 encoding --\n",
    "    binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n",
    "    base64_str = base64.b64encode(binary_str)\n",
    "    return base64_str\n",
    "\n",
    "\n",
    "from PIL import ImageFile\n",
    "import os\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "#TODO image_info should be 2d array, with each row of form id, width, height\n",
    "def append_to_file_seg(filename, results, image_info):\n",
    "    \n",
    "    all_preds = []\n",
    "    \n",
    "    for j, r in enumerate(results):\n",
    "        preds = []\n",
    "        ids = r['class_ids']\n",
    "        masks = r['masks']\n",
    "        scores = r['scores']\n",
    "\n",
    "        img_id = image_info[j][0]\n",
    "        height = image_info[j][2]\n",
    "        width = image_info[j][1]\n",
    "        \n",
    "        preds =''\n",
    "        \n",
    "        for i in range(len(r['class_ids'])):\n",
    "            # masks are stored as a 3d array, <height,width,# examples>, so we need to index into it in a special way\n",
    "            enc_mask = encode_binary_mask(masks[:,:,i].astype(np.bool))\n",
    "            #TODO figure out when class ids are getting converted to a float, patch over for now...\n",
    "            class_name = omni_class_set.iloc[int(ids[i])]['LabelName']\n",
    "            preds += \" \" + \" \".join(map(str,[class_name, scores[i], enc_mask.decode()]))\n",
    "\n",
    "        img_lvl_fields = ','.join(map(str,[img_id,width,height]))\n",
    "        all_preds.append(img_lvl_fields + \",\" + preds)\n",
    "        \n",
    "    with open(filename, 'a') as f: \n",
    "        f.write('\\n'.join(all_preds))\n",
    "        f.write('\\n')\n",
    "        \n",
    "\n",
    "testdir = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "def write_sub_file_seg(filename, batch_size=500, start_index=0):\n",
    "    results = []\n",
    "    image_info = []\n",
    "\n",
    "\n",
    "    for subdir, dirs, files in os.walk(testdir):\n",
    "        for cnt,file in enumerate(files):\n",
    "\n",
    "            #use this if the process broke down at some point and you need to restart midway through ... total hack\n",
    "            if cnt < start_index:\n",
    "                continue\n",
    "\n",
    "            img = skimage.io.imread(os.path.join(subdir, file))\n",
    "\n",
    "            #image id (filename - .png), width, height\n",
    "            image_info.append([file[:-4],img.shape[1],img.shape[0]])\n",
    "\n",
    "            results += ensemble_detect(models, [img], id_mappings)\n",
    "            \n",
    "            if (cnt%batch_size == (batch_size-1)):\n",
    "                print(\"writing to file ... \")\n",
    "                append_to_file_seg(filename, results,image_info)\n",
    "                results = []\n",
    "                image_info = []\n",
    "                print(cnt,\" completed\") #100,000 images in the test set\n",
    "                \n",
    "    print(\"writing final records to file ... \")\n",
    "    append_to_file_seg(filename, results,image_info)\n",
    "    print(cnt,\" completed\")\n",
    "    \n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Start the process from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T23:22:40.357833Z",
     "start_time": "2019-09-29T23:22:40.354283Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "base_filename = 'experts_submission_9_29.csv'\n",
    "\n",
    "if USE_MASKS:\n",
    "    base_filename = 'seg_' + base_filename\n",
    "\n",
    "filename = os.path.join(ROOT_DIR, base_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T23:23:03.124495Z",
     "start_time": "2019-09-29T23:23:02.952227Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOU ONLY WANT THIS IN PLACE FOR THE FIRST RUN ... afterwards it will wipe the file ... NOT GOOD !!!  \n",
    "\n",
    "if USE_MASKS:\n",
    "    with open(filename, 'w+') as f:\n",
    "        f.write('ImageId,ImageWidth,ImageHeight,PredictionString\\n')\n",
    "        \n",
    "    write_sub_file_seg(filename)\n",
    "else:\n",
    "    with open(filename, 'w+') as f:\n",
    "        f.write('ImageId,PredictionString\\n')\n",
    "        \n",
    "    write_sub_file_det(filename)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Resume work at some file number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T16:58:49.107325Z",
     "start_time": "2019-09-09T16:47:57.536052Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "strt_idx = 9500\n",
    "\n",
    "if USE_MASKS:   \n",
    "    write_sub_file_seg(start_index=strt_idx)\n",
    "else:\n",
    "    write_sub_file_det(start_index=strt_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Fix submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-16T16:44:44.776585Z",
     "start_time": "2019-09-16T16:44:44.247576Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(ROOT_DIR, 'submission9_11.csv'))\n",
    "\n",
    "# nu = df['ImageId'].nunique()  # Should be 99999\n",
    "\n",
    "# if len(df) > nu:\n",
    "#     df.drop_duplicates('ImageId', inplace = True)\n",
    "\n",
    "# df.to_csv('submission_9_11_0.csv',index=False)\n",
    "df.iloc[0]['PredictionString']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Run inference on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "testdir = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for subdir, dirs, files in os.walk(testdir):\n",
    "    for i,file in enumerate(files):\n",
    "        results += ensemble_detect(models, [skimage.io.imread(os.path.join(subdir, file))],1, id_offsets)\n",
    "        \n",
    "        if (i%10 == 0):\n",
    "            print(i/1000) #100,000 images in the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T18:50:25.142754Z",
     "start_time": "2019-08-28T18:50:19.987024Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TO USE THIS:\n",
    "# You need to store the images above instead of loading them as a function argument\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for i,r in enumerate(results):\n",
    "    visualize.display_instances(images[i], r['rois'], r['masks'], r['class_ids'], omni_class_set['LabelDescription'].values, r['scores'], show_mask=False)\n",
    "    \n",
    "    cnt += 1\n",
    "    \n",
    "    if cnt > 5:\n",
    "        break   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Build Kaggle Submission File from results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-01T19:33:10.644Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO This cell will probably fail in the future as it assumes that \n",
    "# the body of the calculate_mAP function was executed outside of a function so that the\n",
    "# results and image_ids variables are exposed\n",
    "\n",
    "img_ids = anns_grouped.sum().index.values\n",
    "\n",
    "all_preds = []\n",
    "\n",
    "#DONT KNOW ABOUT ORDERING ANYMORE ...\n",
    "for j, r in enumerate(results):\n",
    "    preds = []\n",
    "    ids = r['class_ids']\n",
    "    boxes = r['rois']\n",
    "    scores = r['scores']\n",
    "    \n",
    "    preds = ''\n",
    "    \n",
    "    for i in range(len(r['class_ids'])):\n",
    "        preds += \" \" + \" \".join(map(str,[omni_class_set.iloc[ids[i]]['LabelName'], scores[i], boxes[i][1],boxes[i][0],boxes[i][3],boxes[i][2]]))\n",
    "    \n",
    "    iid = image_ids[j]\n",
    "    \n",
    "    all_preds.append(img_ids[iid] + \", \" + preds[1:])\n",
    "\n",
    "\n",
    "#TODO write to csv file\n",
    "with open(os.path.join(ROOT_DIR, 'submission.csv'), 'w') as f: \n",
    "    f.write('ImageId,PredictionString\\n')\n",
    "    f.write('\\n'.join(all_preds)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Visualize results for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:33:36.444760Z",
     "start_time": "2019-09-30T15:33:36.433149Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class InferenceConfig(TrainConfig):\n",
    "    NUM_CLASSES = len(omni_class_set)\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "\n",
    "inf_config = InferenceConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:33:47.969468Z",
     "start_time": "2019-09-30T15:33:38.335574Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# random images\n",
    "num_samples = 10\n",
    "\n",
    "image_ids = np.random.choice(dataset.image_ids, num_samples)\n",
    "\n",
    "\n",
    "# single object scenes\n",
    "# image_ids = [28542,16831,26167,1290,1694]\n",
    "\n",
    "# single object with parts scenes\n",
    "# image_ids = [16020,31270,16615,16364,29407,12841,19720]\n",
    "\n",
    "#more complicated scenes\n",
    "# image_ids = [6596,14954,6081,28724,9376]\n",
    "\n",
    "#complicated scenes\n",
    "# image_ids = [30670, 4918,13704,15065,22429,8799]\n",
    "\n",
    "ver_images = []\n",
    "\n",
    "for iid in image_ids:\n",
    "    original_image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset, inf_config, iid, use_mini_mask=False)\n",
    "\n",
    "    #UNCOMMENT THESE LINES TO VISUALIZE\n",
    "#     print(iid)\n",
    "#     visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "#                             dataset.class_names, figsize=(8, 8))\n",
    "    \n",
    "    ver_images.append(original_image)\n",
    "    \n",
    "# [30670, 4918, 6596, 13792]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:33:49.706461Z",
     "start_time": "2019-09-30T15:33:49.663965Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_em(image,iid,mode='all'):\n",
    "\n",
    "    if mode == 'all' :\n",
    "        for midx,model in enumerate(models):\n",
    "            results = model.detect([image], verbose=0)\n",
    "\n",
    "            for i in range(len(results)):\n",
    "                r = results[i]\n",
    "\n",
    "                r['model_id'] = midx\n",
    "                r['class_ids'] = id_mappings[midx](r['class_ids'])\n",
    "                print('Model: ', midx)\n",
    "\n",
    "                visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], omni_class_set['LabelDescription'].values,\n",
    "                                            r['scores'], show_mask=USE_MASKS,figsize=(10, 10))\n",
    "            \n",
    "    if mode == 'all_fulls' :\n",
    "        for midx,model in enumerate(models[10:]):\n",
    "            results = model.detect([image], verbose=0)\n",
    "\n",
    "            for i in range(len(results)):\n",
    "                r = results[i]\n",
    "\n",
    "                r['model_id'] = midx\n",
    "                r['class_ids'] = id_mappings[10](r['class_ids'])\n",
    "                print('Model: ', midx)\n",
    "\n",
    "                visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], omni_class_set['LabelDescription'].values,\n",
    "                                            r['scores'], show_mask=USE_MASKS,figsize=(10, 10))\n",
    "\n",
    "    print(\"----------------- ENSEMBLE ---------------------\")\n",
    "    eresults = ensemble_detect(models, [image], id_mappings)\n",
    "    r = eresults[0]\n",
    "    \n",
    "    if(len(r['class_ids']) > 0):\n",
    "        #hack warning\n",
    "        cids = np.array(list(map(int,r['class_ids'])))\n",
    "        visualize.display_instances(image, r['rois'], r['masks'], cids, omni_class_set['LabelDescription'].values,\n",
    "                                r['scores'], show_mask=USE_MASKS,figsize=(10, 10))\n",
    "\n",
    "\n",
    "    print(\"----------------- Ground Truth ---------------------\")\n",
    "    inf_config = InferenceConfig()\n",
    "    original_image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset, inf_config, iid, use_mini_mask=False)\n",
    "\n",
    "    # visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "    #                             dataset.class_names, figsize=(8, 8))\n",
    "    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                                dataset.class_names,show_mask=USE_MASKS,figsize=(10, 10))\n",
    "\n",
    "\n",
    "    if(len(r[\"class_ids\"]) > 0):\n",
    "        AP, precisions, recalls, overlaps = utils.compute_ap(gt_bbox, gt_class_id, gt_mask, \n",
    "                                                     r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "\n",
    "        print(\"AP: \", AP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T15:36:57.036508Z",
     "start_time": "2019-09-30T15:33:52.439893Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(num_samples):\n",
    "#     visualize_em(ver_images[i],image_ids[i],mode='ensemble')\n",
    "\n",
    "for i in range(num_samples):\n",
    "    visualize_em(ver_images[i],image_ids[i],mode='all_fulls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Evaluate mAP for member models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T14:56:46.176962Z",
     "start_time": "2019-09-23T14:56:46.169578Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eval_single_model(model_path,cset_index=None, mAP_sample_size=250,class_set=None,val_data=None,mask_path=None):\n",
    "\n",
    "    if class_set is None:\n",
    "        class_set = class_sub_sets[cset_index]\n",
    "        \n",
    "    if val_data is None:\n",
    "        anns = st.load_annotations_by_image(class_set,use_masks=USE_MASKS)    \n",
    "        val_data = st.load_dataset(anns, DATA_DIR, class_set, is_train=False,mask_path=mask_path)\n",
    "\n",
    "    class KaggleConfig(TrainConfig):\n",
    "        NUM_CLASSES = len(class_set) + 1 # + 1 for background class\n",
    "\n",
    "    inf_config = KaggleConfig()\n",
    "    \n",
    "    inf_model = modellib.MaskRCNN(mode=\"inference\", config=inf_config, model_dir=MODEL_DIR)\n",
    "\n",
    "    inf_model.load_weights(model_path, by_name=True)\n",
    "    \n",
    "    return u.eval_mAP(inf_model, val_data, inf_config, mAP_sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Single model using recently trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Single evaluation for a single model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T15:00:33.719830Z",
     "start_time": "2019-09-23T14:58:24.898041Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_single_model(os.path.join(MODEL_DIR,'kaggle20190923T0040','mask_rcnn_kaggle_0050.h5'),cset_index=7, mAP_sample_size=250,mask_path=MASK_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Multiple evaluations of a single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T15:06:02.233762Z",
     "start_time": "2019-09-23T15:05:30.699688Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build the validation data set once for faster mAP evaluation\n",
    "\n",
    "cset_index = 7\n",
    "\n",
    "class_set = class_sub_sets[cset_index]\n",
    "        \n",
    "anns = st.load_annotations_by_image(class_set,USE_MASKS)    \n",
    "val_data = st.load_dataset(anns, DATA_DIR, class_set, is_train=False,mask_path=MASK_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T15:11:09.128714Z",
     "start_time": "2019-09-23T15:06:36.026716Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(47,50):\n",
    "    print(i,eval_single_model(os.path.join(MODEL_DIR,'kaggle20190923T0040',\"mask_rcnn_kaggle_00\" + str(i) + \".h5\"),\n",
    "                  class_set=class_set, val_data=val_data, mAP_sample_size=250))\n",
    "\n",
    "# eval_single_model(os.path.join(MODEL_DIR,'kaggle20190903T1053',\"mask_rcnn_kaggle_0165.h5\"),\n",
    "#                   class_set=class_set, val_data=val_data, mAP_sample_size=250)\n",
    "    \n",
    "# copy recently trained model to models directory\n",
    "\n",
    "#model from epoch 164 had mAP of 0.189, val_loss of 2.00\n",
    "#model from epoch 165 had mAP of 0.271, val_loss of 1.322\n",
    "#model from epoch 166 had mAP of 0.29, val_loss of 1.551\n",
    "#model from epoch 74, had mAP of 0.201, val_loss of 4.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### All models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Load models (duplicates cell from above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_paths = [os.path.join(DATA_DIR,'models','cset_' + str(i) + '_model.h5') for i in range(6)]\n",
    "\n",
    "models = load_member_models(model_paths, class_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Run all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T17:10:25.771066Z",
     "start_time": "2019-09-03T16:55:54.646866Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,mpath in enumerate(model_paths):\n",
    "    print(i, eval_single_model(mpath,cset_index=i,mask_path=MASK_DIR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "328px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
