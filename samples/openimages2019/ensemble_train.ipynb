{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Train on OpenImages Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T19:11:39.744495Z",
     "start_time": "2019-09-01T19:11:35.864855Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "from openimages2019 import setup as st\n",
    "from openimages2019 import utils as u\n",
    "\n",
    "from skimage.draw import rectangle\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"../data\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(DATA_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "#Make GPUs visible\n",
    "!export HIP_VISIBLE_DEVICES=1,2,3\n",
    "\n",
    "#Set which GPU devices' memory should be accessible to running GPUs\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2,3\"\n",
    "\n",
    "\n",
    "\n",
    "import mlflow\n",
    "#add mlflow stuff\n",
    "\n",
    "MLFLOW_SERVER = 'occ01ap200.na.simplot.com'\n",
    "\n",
    "os.environ['NO_PROXY'] = MLFLOW_SERVER\n",
    "mlflow.tracking.set_tracking_uri('http://' + MLFLOW_SERVER + ':5005')\n",
    "EXPERIMENT_NAME = 'kaggle_openimage_mask_rcnn_v1.0'\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# os.environ['AZURE_STORAGE_ACCESS_KEY'] = ''\n",
    "\n",
    "\n",
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:52:07.338097Z",
     "start_time": "2019-09-03T16:52:07.304141Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TrainConfig(Config):\n",
    "    \n",
    "    NAME = \"kaggle\"\n",
    "    GPU_COUNT = 3\n",
    "    IMAGES_PER_GPU = 3\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    \n",
    "\n",
    "def log_params(pz):\n",
    "    for k,v in pz.items():\n",
    "        mlflow.log_param(k,v)\n",
    "\n",
    "        \n",
    "\n",
    "def train(model, inf_config, train_data, val_data, params):\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "#         es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "        \n",
    "        model.train(train_data, val_data, \n",
    "                    learning_rate=params['learning_rate'], \n",
    "                    epochs=params['epochs'],\n",
    "                    layers=params['layers']\n",
    "#                     layers=params['layers'],\n",
    "#                     custom_callbacks=[es]\n",
    "                   )\n",
    "\n",
    "        log_params(params)\n",
    "        \n",
    "        #Inference to get mAP\n",
    "        inf_model = modellib.MaskRCNN(mode=\"inference\", config=inf_config, model_dir=MODEL_DIR)\n",
    "        model_path = inf_model.find_last()\n",
    "        inf_model.load_weights(model_path, by_name=True)\n",
    "        mAP = u.eval_mAP(inf_model, val_data, inf_config, params['mAP_sample_size'])\n",
    "        \n",
    "        mlflow.log_metric('mAP', mAP)\n",
    "        mlflow.log_param('Model Path', model_path)\n",
    "        \n",
    "        # pickle.dump(clf,open(model_filepath,'wb'))\n",
    "        # mlflow.log_artifact(model_filepath)\n",
    "        \n",
    "        return model_path, mAP\n",
    "\n",
    "    \n",
    "    \n",
    "def train_on_class_subset(class_set, params, init_with=\"coco\"):\n",
    "    \n",
    "    class KaggleConfig(TrainConfig):\n",
    "#         STEPS_PER_EPOCH = params['STEPS_PER_EPOCH'] if 'STEPS_PER_EPOCH' in params else 500\n",
    "        NUM_CLASSES = len(class_set) + 1 # + 1 for background class\n",
    "\n",
    "    class InferenceConfig(KaggleConfig):\n",
    "        GPU_COUNT = 1\n",
    "\n",
    "    train_config = KaggleConfig()\n",
    "    inf_config = InferenceConfig()    \n",
    "\n",
    "    model = modellib.MaskRCNN(mode=\"training\", config=train_config, model_dir=MODEL_DIR)\n",
    "\n",
    "    if init_with == \"imagenet\":\n",
    "        model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "    elif init_with == \"coco\":\n",
    "        model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                           exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                    \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "    elif init_with == \"last\":\n",
    "        model.load_weights(model.find_last(), by_name=True)\n",
    "    \n",
    "    anns = st.load_annotations_by_image(class_set)\n",
    "    train_data = st.load_dataset(anns, DATA_DIR, class_set, is_train=True)\n",
    "    val_data = st.load_dataset(anns, DATA_DIR, class_set, is_train=False)\n",
    "\n",
    "    return train(model, inf_config, train_data, val_data, params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition the classes according to frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T19:12:33.514368Z",
     "start_time": "2019-09-01T19:11:43.600857Z"
    }
   },
   "outputs": [],
   "source": [
    "class_sets = st.partition_classes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Determine number of images containing any object of a class set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T20:23:49.528048Z",
     "start_time": "2019-08-28T20:21:41.814881Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "anns = st.load_annotations_by_image()\n",
    "\n",
    "val_anns = anns[anns['RelativePath'].str.contains('validation',regex=False)]\n",
    "train_anns = anns[anns['RelativePath'].str.contains('train',regex=False)]\n",
    "\n",
    "def count_em(anns):\n",
    "    rval = []\n",
    "    \n",
    "    for cs in class_sets:\n",
    "        z = anns[anns['LabelName'].isin(cs['LabelName'].values)]['ImageID'].nunique()\n",
    "        rval.append(z)\n",
    "        \n",
    "    return rval\n",
    "\n",
    "num_class_set_images_train = count_em(train_anns)\n",
    "num_class_set_images_val = count_em(val_anns)\n",
    "\n",
    "display(num_class_set_images_train)\n",
    "display(num_class_set_images_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model on each partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-29T23:14:21.596Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "        'learning_rate' : 0.001,\n",
    "        'epochs' : 100,\n",
    "        'layers' : 'heads',\n",
    "        'mAP_sample_size' : 250,\n",
    "        'GPU_COUNT' : 3,\n",
    "        'IMAGES_PER_GPU' : 4,\n",
    "        'IMAGE_MIN_DIM' : 512,\n",
    "        'IMAGE_MAX_DIM' : 512\n",
    "         }\n",
    "\n",
    "#TODO log the entire Config object with mlflow, not just params\n",
    "for i,class_set in enumerate(class_sets):\n",
    "    params['class_set_index'] = i\n",
    "    train_on_class_subset(class_set, params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-06T20:48:33.128Z"
    }
   },
   "outputs": [],
   "source": [
    "#Note that changes to ALL_CAPS properties in params do not affect the model.  You will need to change the corresponding\n",
    "# values above (e.g in TrainConfig) to have any effect.\n",
    "\n",
    "params = {\n",
    "        'learning_rate' : 0.001,\n",
    "        'epochs' : 300,\n",
    "        'layers' : 'all',\n",
    "        'mAP_sample_size' : 250,\n",
    "        'GPU_COUNT' : 3,\n",
    "        'IMAGES_PER_GPU' : 4,\n",
    "        'IMAGE_MIN_DIM' : 512,\n",
    "        'IMAGE_MAX_DIM' : 512\n",
    "         }\n",
    "\n",
    "set_num = 2\n",
    "\n",
    "params['class_set_index'] = set_num\n",
    "train_on_class_subset(class_sets[set_num], params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T20:34:45.434332Z",
     "start_time": "2019-09-04T18:25:31.770224Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "        'learning_rate' : 0.001,\n",
    "        'epochs' : 200,\n",
    "        'layers' : 'heads',\n",
    "        'mAP_sample_size' : 250,\n",
    "        'GPU_COUNT' : 3,\n",
    "        'IMAGES_PER_GPU' : 3,\n",
    "        'IMAGE_MIN_DIM' : 512,\n",
    "        'IMAGE_MAX_DIM' : 512\n",
    "         }\n",
    "\n",
    "\n",
    "for i in [1,3,4,5]:\n",
    "    params['class_set_index'] = i\n",
    "    train_on_class_subset(class_sets[i], params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "295px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
