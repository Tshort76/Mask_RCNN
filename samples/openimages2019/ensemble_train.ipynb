{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T21:29:07.096068Z",
     "start_time": "2019-09-23T21:29:03.107967Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "from openimages2019 import setup as st\n",
    "from openimages2019 import utils as u\n",
    "\n",
    "from skimage.draw import rectangle\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"../data\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(DATA_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "MASK_DIR = os.path.join(DATA_DIR, \"segmentation\")\n",
    "\n",
    "\n",
    "#################################\n",
    "USE_MASKS = True\n",
    "#################################\n",
    "\n",
    "#Make GPUs visible\n",
    "!export HIP_VISIBLE_DEVICES=1,2,3\n",
    "\n",
    "#Set which GPU devices' memory should be accessible to running GPUs\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2,3\"\n",
    "\n",
    "\n",
    "import mlflow\n",
    "#add mlflow stuff\n",
    "\n",
    "MLFLOW_SERVER = 'occ01ap200.na.simplot.com'\n",
    "\n",
    "os.environ['NO_PROXY'] = MLFLOW_SERVER\n",
    "mlflow.tracking.set_tracking_uri('http://' + MLFLOW_SERVER + ':5005')\n",
    "EXPERIMENT_NAME = 'kaggle_openimage_mask_rcnn_v1.0'\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# os.environ['AZURE_STORAGE_ACCESS_KEY'] = ''\n",
    "\n",
    "\n",
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define augmentation and train functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Example taken from https://imgaug.readthedocs.io/en/latest/source/examples_basics.html\n",
    "# not actually used ... though\n",
    "\n",
    "import numpy as np\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "\n",
    "ia.seed(1)\n",
    "\n",
    "# Example batch of images.\n",
    "# The array has shape (32, 64, 64, 3) and dtype uint8.\n",
    "images = np.array(\n",
    "    [ia.quokka(size=(64, 64)) for _ in range(32)],\n",
    "    dtype=np.uint8\n",
    ")\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5), # horizontal flips\n",
    "    iaa.Crop(percent=(0, 0.1)), # random crops\n",
    "    # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "    # But we only blur about 50% of all images.\n",
    "    iaa.Sometimes(0.5,\n",
    "        iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "    ),\n",
    "    # Strengthen or weaken the contrast in each image.\n",
    "    iaa.ContrastNormalization((0.75, 1.5)),\n",
    "    # Add gaussian noise.\n",
    "    # For 50% of all images, we sample the noise once per pixel.\n",
    "    # For the other 50% of all images, we sample the noise per pixel AND\n",
    "    # channel. This can change the color (not only brightness) of the\n",
    "    # pixels.\n",
    "    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "    # Make some images brighter and some darker.\n",
    "    # In 20% of all cases, we sample the multiplier once per channel,\n",
    "    # which can end up changing the color of the images.\n",
    "    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "    # Apply affine transformations to each image.\n",
    "    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "        rotate=(-25, 25),\n",
    "        shear=(-8, 8)\n",
    "    )\n",
    "], random_order=True) # apply augmenters in random order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T21:30:40.131764Z",
     "start_time": "2019-09-23T21:30:40.099454Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import imgaug\n",
    "\n",
    "class TrainConfig(Config):\n",
    "    \n",
    "    NAME = \"kaggle\"\n",
    "    GPU_COUNT = 3\n",
    "    IMAGES_PER_GPU = 4\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    \n",
    "\n",
    "def log_params(pz):\n",
    "    for k,v in pz.items():\n",
    "        mlflow.log_param(k,v)\n",
    "\n",
    "# Image Augmentation ... pulled from coco example\n",
    "# Right/Left flip 50% of the time\n",
    "augmentation = imgaug.augmenters.Fliplr(0.5)\n",
    "        \n",
    "        \n",
    "def train(model, inf_config, train_data, val_data, params):\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "#         es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "        \n",
    "        model.train(train_data, val_data, \n",
    "                    learning_rate=params['learning_rate'], \n",
    "                    epochs=params['epochs'],\n",
    "                    augmentation=augmentation,\n",
    "                    layers=params['layers']\n",
    "#                     layers=params['layers'],\n",
    "#                     custom_callbacks=[es]\n",
    "                   )\n",
    "\n",
    "        log_params(params)\n",
    "        \n",
    "        #Inference to get mAP\n",
    "        inf_model = modellib.MaskRCNN(mode=\"inference\", config=inf_config, model_dir=MODEL_DIR)\n",
    "        model_path = inf_model.find_last()\n",
    "        inf_model.load_weights(model_path, by_name=True)\n",
    "        mAP = u.eval_mAP(inf_model, val_data, inf_config, params['mAP_sample_size'])\n",
    "        \n",
    "        mlflow.log_metric('mAP', mAP)\n",
    "        mlflow.log_param('Model Path', model_path)\n",
    "        \n",
    "        return model_path, mAP\n",
    "\n",
    "    \n",
    "    \n",
    "def train_on_class_subset(class_set, params, init_with=\"coco\"):\n",
    "    \n",
    "    class KaggleConfig(TrainConfig):\n",
    "        NUM_CLASSES = len(class_set) + 1 # + 1 for background class\n",
    "\n",
    "    class InferenceConfig(KaggleConfig):\n",
    "        GPU_COUNT = 1\n",
    "\n",
    "    train_config = KaggleConfig()\n",
    "    inf_config = InferenceConfig()    \n",
    "\n",
    "    model = modellib.MaskRCNN(mode=\"training\", config=train_config, model_dir=MODEL_DIR)\n",
    "\n",
    "    if init_with == \"imagenet\":\n",
    "        model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "    elif init_with == \"coco\":\n",
    "        model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                           exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                    \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "    else: #use a base model other than coco\n",
    "        model.load_weights(init_with, by_name=True,\n",
    "                          exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                    \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "    \n",
    "    \n",
    "    if USE_MASKS:\n",
    "        anns = st.load_annotations_by_image(class_set, use_masks=True)\n",
    "        train_data = st.load_dataset(anns, DATA_DIR, class_set, is_train=True,mask_path=MASK_DIR)\n",
    "        val_data = st.load_dataset(anns, DATA_DIR, class_set, is_train=False, mask_path=MASK_DIR)\n",
    "    else:\n",
    "        anns = st.load_annotations_by_image(class_set)\n",
    "        train_data = st.load_dataset(anns, DATA_DIR, class_set, is_train=True)\n",
    "        val_data = st.load_dataset(anns, DATA_DIR, class_set, is_train=False)\n",
    "    \n",
    "    \n",
    "    return train(model, inf_config, train_data, val_data, params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition the classes according to frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T21:29:55.295893Z",
     "start_time": "2019-09-23T21:29:22.204215Z"
    }
   },
   "outputs": [],
   "source": [
    "# class_sets = st.partition_classes()\n",
    "\n",
    "if USE_MASKS:\n",
    "    all_classes = st.load_classes(path_to_csv=os.path.join(DATA_DIR,'seg_class_descriptions.csv'))\n",
    "    anns = st.load_annotations_by_image(classes=all_classes, use_masks=True)\n",
    "else:\n",
    "    all_classes = st.load_classes()\n",
    "    anns = st.load_annotations_by_image(classes=all_classes, use_masks=False)\n",
    "\n",
    "    \n",
    "cnts = anns['LabelName'].value_counts()\n",
    "\n",
    "class_sets = []\n",
    "\n",
    "n_partitions = 10\n",
    "\n",
    "p_size = int(len(all_classes) / n_partitions)\n",
    "\n",
    "for i in range(n_partitions):\n",
    "    s = i*p_size\n",
    "    idxs = cnts.iloc[s:(s+p_size)].index.values\n",
    "    tmp_set = all_classes[all_classes['LabelName'].isin(idxs)]\n",
    "    tmp_set = tmp_set.reset_index()\n",
    "    tmp_set['LabelID'] = tmp_set.index + 1\n",
    "    class_sets.append(tmp_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Train all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-21T16:08:45.649058Z",
     "start_time": "2019-09-20T21:49:06.102783Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "        'learning_rate' : 0.001,\n",
    "        'epochs' : 50,\n",
    "        'layers' : 'heads',\n",
    "        'mAP_sample_size' : 250,\n",
    "        'GPU_COUNT' : 4,\n",
    "        'IMAGES_PER_GPU' : 4,\n",
    "        'IMAGE_MIN_DIM' : 512,\n",
    "        'IMAGE_MAX_DIM' : 512\n",
    "         }\n",
    "\n",
    "base_model = os.path.join(DATA_DIR, \"models/omni_seg_base_0586.h5\")\n",
    "\n",
    "#TODO log the entire Config object with mlflow, not just params\n",
    "for i,class_set in enumerate(class_sets):\n",
    "    params['class_set_index'] = i\n",
    "#     train_on_class_subset(class_set, params)\n",
    "    train_on_class_subset(class_set, params, init_with=base_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T08:27:44.451361Z",
     "start_time": "2019-09-23T21:31:46.652437Z"
    }
   },
   "outputs": [],
   "source": [
    "#Note that changes to ALL_CAPS properties in params do not affect the model.  You will need to change the corresponding\n",
    "# values above (e.g in TrainConfig) to have any effect.\n",
    "\n",
    "params = {\n",
    "        'learning_rate' : 0.001,\n",
    "        'epochs' : 100,\n",
    "        'layers' : 'heads',\n",
    "        'mAP_sample_size' : 250,\n",
    "        'GPU_COUNT' : 3,\n",
    "        'IMAGES_PER_GPU' : 4,\n",
    "        'IMAGE_MIN_DIM' : 512,\n",
    "        'IMAGE_MAX_DIM' : 512\n",
    "         }\n",
    "\n",
    "# base_model = os.path.join(DATA_DIR, \"models/omni_seg_base_0586.h5\")\n",
    "\n",
    "set_num = 9\n",
    "\n",
    "params['class_set_index'] = set_num\n",
    "train_on_class_subset(class_sets[set_num], params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Train a subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T18:53:22.228121Z",
     "start_time": "2019-09-21T16:13:46.152342Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "        'learning_rate' : 0.001,\n",
    "        'epochs' : 50,\n",
    "        'layers' : 'heads',\n",
    "        'mAP_sample_size' : 250,\n",
    "        'GPU_COUNT' : 3,\n",
    "        'IMAGES_PER_GPU' : 4,\n",
    "        'IMAGE_MIN_DIM' : 512,\n",
    "        'IMAGE_MAX_DIM' : 512\n",
    "         }\n",
    "\n",
    "base_model = os.path.join(DATA_DIR, \"models/omni_seg_base_0586.h5\")\n",
    "\n",
    "for i in range(2,10):\n",
    "    params['class_set_index'] = i\n",
    "#     train_on_class_subset(class_set, params)\n",
    "    train_on_class_subset(class_sets[i], params, init_with=base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# MISC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Determine number of images containing any object of a class set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "anns = st.load_annotations_by_image()\n",
    "\n",
    "val_anns = anns[anns['RelativePath'].str.contains('validation',regex=False)]\n",
    "train_anns = anns[anns['RelativePath'].str.contains('train',regex=False)]\n",
    "\n",
    "def count_em(anns):\n",
    "    rval = []\n",
    "    \n",
    "    for cs in class_sets:\n",
    "        z = anns[anns['LabelName'].isin(cs['LabelName'].values)]['ImageID'].nunique()\n",
    "        rval.append(z)\n",
    "        \n",
    "    return rval\n",
    "\n",
    "num_class_set_images_train = count_em(train_anns)\n",
    "num_class_set_images_val = count_em(val_anns)\n",
    "\n",
    "display(num_class_set_images_train)\n",
    "display(num_class_set_images_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "295px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
