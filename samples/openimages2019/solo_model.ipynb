{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic imports for Mask R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T21:32:59.230287Z",
     "start_time": "2019-10-04T21:32:56.199083Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "from openimages2019 import setup as st\n",
    "\n",
    "from skimage import transform\n",
    "import skimage.io\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"../data\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(DATA_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "#Make GPUs visible\n",
    "!export HIP_VISIBLE_DEVICES=1,2,3\n",
    "\n",
    "#Set which GPU devices' memory should be accessible to running GPUs\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2,3\"\n",
    "\n",
    "\n",
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Segmentation vs Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T21:41:03.398975Z",
     "start_time": "2019-10-04T21:41:03.395636Z"
    }
   },
   "outputs": [],
   "source": [
    "USE_MASKS = False\n",
    "\n",
    "MASK_DIR  = os.path.join(DATA_DIR,'segmentation')\n",
    "CLASS_DESC_CSV = os.path.join(DATA_DIR, 'seg_class_descriptions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T21:41:06.050221Z",
     "start_time": "2019-10-04T21:41:05.976935Z"
    }
   },
   "outputs": [],
   "source": [
    "class_descriptions = st.load_classes()\n",
    "\n",
    "class_descriptions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T20:53:55.914459Z",
     "start_time": "2019-10-04T20:38:38.170506Z"
    }
   },
   "outputs": [],
   "source": [
    "if USE_MASKS:\n",
    "    class_descriptions = st.load_classes(path_to_csv=CLASS_DESC_CSV)\n",
    "    \n",
    "    anns = st.load_annotations_by_image(class_descriptions, use_masks=True)\n",
    "    train_data = st.load_dataset(anns, DATA_DIR, class_descriptions, is_train=True,mask_path=MASK_DIR)\n",
    "    val_data = st.load_dataset(anns, DATA_DIR, class_descriptions, is_train=False, mask_path=MASK_DIR)\n",
    "else:\n",
    "    class_descriptions = st.load_classes()\n",
    "    \n",
    "    anns = st.load_annotations_by_image(class_descriptions)\n",
    "    train_data = st.load_dataset(anns, DATA_DIR, class_descriptions, is_train=True)\n",
    "    val_data = st.load_dataset(anns, DATA_DIR, class_descriptions, is_train=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T20:53:55.921896Z",
     "start_time": "2019-10-04T20:53:55.917570Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class KaggleConfig(Config):\n",
    "    \n",
    "    NAME = \"kaggle\"\n",
    "\n",
    "    GPU_COUNT = 3\n",
    "    IMAGES_PER_GPU = 4  # TODO how many can we use, authors had 2 for 12 GB, we have 32 GB so ...\n",
    "    \n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + len(class_descriptions)  # + 1 for background\n",
    "\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    \n",
    "    # Skip detections with < 90% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "    \n",
    "config = KaggleConfig()\n",
    "# config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model and load prior weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T20:54:09.702647Z",
     "start_time": "2019-10-04T20:53:55.924282Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T20:54:22.871913Z",
     "start_time": "2019-10-04T20:54:09.704913Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if USE_MASKS:\n",
    "    init_with = os.path.join(MODEL_DIR, \"kaggle20190923T1355/mask_rcnn_kaggle_0822.h5\")\n",
    "else:\n",
    "    init_with = \"coco\"\n",
    "\n",
    "if init_with == \"coco\":\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    model.load_weights(model.find_last(), by_name=True)\n",
    "else:\n",
    "    model.load_weights(init_with, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T21:09:12.682814Z",
     "start_time": "2019-10-04T20:54:22.874042Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip3 install imgaug\n",
    "import imgaug\n",
    "\n",
    "# Image Augmentation ... pulled from coco example\n",
    "# Right/Left flip 50% of the time\n",
    "augmentation = imgaug.augmenters.Fliplr(0.5)\n",
    "\n",
    "n_epochs = 1 \n",
    "\n",
    "model.train(train_data, val_data, \n",
    "                learning_rate= 0.001, \n",
    "                epochs=n_epochs, \n",
    "                layers='heads',\n",
    "                augmentation=augmentation)\n",
    "\n",
    "# model.train(train_data, val_data, \n",
    "#                 learning_rate= 0.0001, \n",
    "#                 epochs=n_epochs, \n",
    "#                 layers='all',\n",
    "#                 augmentation=augmentation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T21:41:44.438427Z",
     "start_time": "2019-10-04T21:41:40.169438Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class InferenceConfig(Config):\n",
    "    NAME = 'KaggleInf'\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 1 + len(class_descriptions)\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "if USE_MASKS:\n",
    "    model_path = os.path.join(ROOT_DIR, \"logs/kaggle20190923T1355/mask_rcnn_kaggle_0822.h5\")\n",
    "else:\n",
    "    model_path = os.path.join(ROOT_DIR, \"logs/kaggle20191004T1454/mask_rcnn_kaggle_0001.h5\")\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T21:13:27.553490Z",
     "start_time": "2019-10-04T21:13:27.546820Z"
    }
   },
   "outputs": [],
   "source": [
    "def visual_check(image_ids, dataset):\n",
    "    for iid in image_ids:\n",
    "        original_image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset, inference_config, iid, use_mini_mask=False)\n",
    "\n",
    "        # might need to pass use_mask=False if USE_MASKS=FALSE ... maybe\n",
    "        print('--------------\\n GROUND TRUTH \\n--------------')\n",
    "        visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                                dataset.class_names, figsize=(8, 8))\n",
    "\n",
    "        r = model.detect([original_image], verbose=0)[0]\n",
    "\n",
    "        print('--------------\\n PREDICTION \\n--------------')\n",
    "        visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                                    dataset.class_names, r['scores'],figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T21:13:38.220685Z",
     "start_time": "2019-10-04T21:13:29.817013Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = val_data\n",
    "\n",
    "visual_check(np.random.choice(dataset.image_ids, 5), dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T21:16:24.445760Z",
     "start_time": "2019-10-04T21:16:08.666965Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "num_images = 50\n",
    "\n",
    "image_ids = np.random.choice(val_data.image_ids, num_images)\n",
    "\n",
    "#each input is a tuple of form : image, image_meta, gt_class_id, gt_bbox, gt_mask\n",
    "inputs = [modellib.load_image_gt(val_data, inference_config, iid, use_mini_mask=False) for iid in image_ids]\n",
    "\n",
    "APs = []\n",
    "\n",
    "n = inference_config.BATCH_SIZE\n",
    "\n",
    "for i in range(0,len(image_ids),n): \n",
    "\n",
    "    curr_inputs = inputs[i:i+n]\n",
    "    \n",
    "    results = model.detect([inp[0] for inp in curr_inputs], verbose=0)\n",
    "    \n",
    "    for j in range(len(results)):\n",
    "        r = results[j]\n",
    "        # Compute AP\n",
    "        AP, precisions, recalls, overlaps =\\\n",
    "            utils.compute_ap(curr_inputs[j][3], curr_inputs[j][2], curr_inputs[j][4],\n",
    "                             r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "        APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode instance segmentation map (from kaggle competition website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# container does not include this library by default, will need to run this once\n",
    "# !pip install pycocotools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define batch-write functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T21:18:13.235074Z",
     "start_time": "2019-10-04T21:18:13.213285Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "import base64\n",
    "from pycocotools import _mask as coco_mask\n",
    "import typing as t\n",
    "import zlib\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def encode_binary_mask(mask: np.ndarray):\n",
    "\n",
    "     # check input mask --\n",
    "    if mask.dtype != np.bool:\n",
    "        raise ValueError(\n",
    "           \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n",
    "           mask.dtype)\n",
    "\n",
    "    mask = np.squeeze(mask)\n",
    "    if len(mask.shape) != 2:\n",
    "        raise ValueError(\n",
    "           \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n",
    "           mask.shape)\n",
    "\n",
    "     # convert input mask to expected COCO API input --\n",
    "    mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
    "    mask_to_encode = mask_to_encode.astype(np.uint8)\n",
    "    mask_to_encode = np.asfortranarray(mask_to_encode)\n",
    "\n",
    "    # RLE encode mask --\n",
    "    encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n",
    "\n",
    "    # compress and base64 encoding --\n",
    "    binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n",
    "    base64_str = base64.b64encode(binary_str)\n",
    "    return base64_str\n",
    "\n",
    "#image_info should be 2d array, with each row of form id, width, height\n",
    "def segmentation_append(filename, results, image_info):\n",
    "    \n",
    "    all_preds = []\n",
    "    \n",
    "    for j, r in enumerate(results):\n",
    "        preds = []\n",
    "        ids = r['class_ids']\n",
    "        masks = r['masks']\n",
    "        scores = r['scores']\n",
    "\n",
    "        img_id = image_info[j][0]\n",
    "        height = image_info[j][2]\n",
    "        width = image_info[j][1]\n",
    "        \n",
    "        preds =''\n",
    "\n",
    "        for i in range(len(r['class_ids'])):\n",
    "            # masks are stored as a 3d array, <height,width,# examples>, so we need to index into it in a special way\n",
    "            enc_mask = encode_binary_mask(masks[:,:,i])\n",
    "            #subtract 1 to compensate for the background\n",
    "            class_name = class_descriptions.iloc[ids[i]-1]['LabelName']\n",
    "            preds += \" \" + \" \".join(map(str,[class_name, scores[i], enc_mask.decode()]))\n",
    "\n",
    "        img_lvl_fields = ','.join(map(str,[img_id,width,height]))\n",
    "        all_preds.append(img_lvl_fields + \",\" + preds)\n",
    "        \n",
    "    with open(filename, 'a') as f: \n",
    "        f.write('\\n'.join(all_preds))\n",
    "        f.write('\\n')\n",
    "\n",
    "        \n",
    "def detection_append(filename, results, image_info):\n",
    "    all_preds = []\n",
    "    \n",
    "    for j, r in enumerate(results):\n",
    "        preds = []\n",
    "        ids = r['class_ids']\n",
    "        boxes = r['rois']\n",
    "        scores = r['scores']\n",
    "\n",
    "        img_id = image_info[j][0]\n",
    "        height = image_info[j][2]\n",
    "        width = image_info[j][1]\n",
    "        \n",
    "        preds = ''\n",
    "\n",
    "        for i in range(len(r['class_ids'])):\n",
    "            xmin = max(boxes[i][1] / width , 0.0)\n",
    "            ymin = max(boxes[i][0] / height, 0.0)\n",
    "            xmax = min(boxes[i][3] / width, 1.0)\n",
    "            ymax = min(boxes[i][2] / height, 1.0)\n",
    "            \n",
    "            preds += \" \" + \" \".join(map(str,[class_descriptions.iloc[ids[i]-1]['LabelName'], scores[i], xmin,ymin,xmax,ymax]))\n",
    "\n",
    "        all_preds.append(img_id + \",\" + preds)\n",
    "        \n",
    "    with open(filename, 'a') as f: \n",
    "        f.write('\\n'.join(all_preds))\n",
    "        f.write('\\n')\n",
    "\n",
    "    \n",
    "appender = segmentation_append if USE_MASKS else detection_append    \n",
    "\n",
    "testdir = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "def write_sub_file(filename, batch_size=500, start_index=0):\n",
    "    results = []\n",
    "    image_info = []\n",
    "\n",
    "\n",
    "    for subdir, dirs, files in os.walk(testdir):\n",
    "        for cnt,file in enumerate(files):\n",
    "\n",
    "            #use this if the process broke down at some point and you need to restart midway through ... total hack\n",
    "            if cnt < start_index:\n",
    "                continue\n",
    "\n",
    "            img = skimage.io.imread(os.path.join(subdir, file))\n",
    "\n",
    "            #filename, width, height\n",
    "            image_info.append([file[:-4],img.shape[1],img.shape[0]])\n",
    "\n",
    "            results += model.detect([img], verbose=0)\n",
    "\n",
    "            if (cnt%batch_size == (batch_size-1)):\n",
    "                print(\"writing to file ... \")\n",
    "                appender(filename, results,image_info)\n",
    "                results = []\n",
    "                image_info = []\n",
    "                print(cnt,\" completed\") #100,000 images in the test set\n",
    "                \n",
    "    print(\"writing final records to file ... \")\n",
    "    append_to_file(filename, results,image_info)\n",
    "    print(cnt,\" completed\")\n",
    "    \n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute batch writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T21:17:47.726325Z",
     "start_time": "2019-10-04T21:17:47.723280Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = os.path.join(ROOT_DIR, 'det_submission_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the entire file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T21:18:28.977811Z",
     "start_time": "2019-10-04T21:18:15.923038Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(filename, 'w+') as f:\n",
    "    f.write('ImageId,ImageWidth,ImageHeight,PredictionString\\n')\n",
    "    \n",
    "write_sub_file(filename, start_index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume writing the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T21:18:47.897337Z",
     "start_time": "2019-10-04T21:18:41.427413Z"
    }
   },
   "outputs": [],
   "source": [
    "# use X + 1 , where X is from the 'X completed' statement above\n",
    "write_sub_file(filename, start_index=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(submission_file)\n",
    "\n",
    "# nu = df['ImageId'].nunique()  # Should be 99999\n",
    "\n",
    "# if len(df) > nu\n",
    "#     df.drop_duplicates('ImageId', inplace = True)\n",
    "\n",
    "# df.to_csv('submission_9_11_0.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "295px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
