{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Train on OpenImages Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T20:50:05.417548Z",
     "start_time": "2019-08-15T20:50:02.079546Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "from openimages2019 import setup as st\n",
    "from openimages2019 import utils as u\n",
    "\n",
    "from skimage.draw import rectangle\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"../data\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(DATA_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "#Make GPUs visible\n",
    "!export HIP_VISIBLE_DEVICES=0,1,2,3\n",
    "\n",
    "\n",
    "\n",
    "import mlflow\n",
    "#add mlflow stuff\n",
    "\n",
    "MLFLOW_SERVER = 'occ01ap200.na.simplot.com'\n",
    "\n",
    "os.environ['NO_PROXY'] = MLFLOW_SERVER\n",
    "mlflow.tracking.set_tracking_uri('http://' + MLFLOW_SERVER + ':5005')\n",
    "EXPERIMENT_NAME = 'kaggle_openimage_mask_rcnn_v1.0'\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# os.environ['AZURE_STORAGE_ACCESS_KEY'] = ''\n",
    "\n",
    "\n",
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T20:55:53.332335Z",
     "start_time": "2019-08-15T20:55:53.319549Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TrainConfig(Config):\n",
    "    \n",
    "    NAME = \"kaggle\"\n",
    "    GPU_COUNT = 4\n",
    "    IMAGES_PER_GPU = 2\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    STEPS_PER_EPOCH = 500\n",
    "    \n",
    "\n",
    "def log_params(pz):\n",
    "    for k,v in pz.items():\n",
    "        mlflow.log_param(k,v)\n",
    "\n",
    "        \n",
    "\n",
    "def train(model, inf_config, train_data, val_data, params):\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        model.train(train_data, val_data, \n",
    "                    learning_rate=params['learning_rate'], \n",
    "                    epochs=params['epochs'], \n",
    "                    layers=params['layers'])\n",
    "\n",
    "        log_params(params)\n",
    "        \n",
    "        #Inference to get mAP\n",
    "        inf_model = modellib.MaskRCNN(mode=\"inference\", config=inf_config, model_dir=MODEL_DIR)\n",
    "        model_path = inf_model.find_last()\n",
    "        inf_model.load_weights(model_path, by_name=True)\n",
    "        mAP = u.eval_mAP(inf_model, val_data, inf_config, params['mAP_sample_size'])\n",
    "        \n",
    "        mlflow.log_metric('mAP', mAP)\n",
    "        mlflow.log_param('Model Path', model_path)\n",
    "        \n",
    "        # pickle.dump(clf,open(model_filepath,'wb'))\n",
    "        # mlflow.log_artifact(model_filepath)\n",
    "        \n",
    "        return model_path, mAP\n",
    "\n",
    "    \n",
    "    \n",
    "def train_on_class_subset(class_set, params, init_with=\"coco\"):\n",
    "    \n",
    "    class KaggleConfig(TrainConfig):\n",
    "        NUM_CLASSES = len(class_set) + 1 # + 1 for background class\n",
    "\n",
    "    class InferenceConfig(KaggleConfig):\n",
    "        GPU_COUNT = 1\n",
    "        BATCH_SIZE = 10\n",
    "\n",
    "    train_config = KaggleConfig()\n",
    "    inf_config = InferenceConfig()    \n",
    "\n",
    "    model = modellib.MaskRCNN(mode=\"training\", config=train_config, model_dir=MODEL_DIR)\n",
    "\n",
    "    if init_with == \"imagenet\":\n",
    "        model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "    elif init_with == \"coco\":\n",
    "        model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                           exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                    \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "    elif init_with == \"last\":\n",
    "        model.load_weights(model.find_last(), by_name=True)\n",
    "    \n",
    "    anns = st.load_annotations_by_image(class_set)\n",
    "    train_data = st.load_dataset(anns, DATA_DIR, class_set, is_train=True)\n",
    "    val_data = st.load_dataset(anns, DATA_DIR, class_set, is_train=False)\n",
    "\n",
    "    return train(model, inf_config, train_data, val_data, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition the classes according to frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = st._get_sql_conn()\n",
    "\n",
    "all_classes = st.load_classes(conn)\n",
    "bboxes = pd.read_sql(\"SELECT ImageID, XMax, XMin, YMin, YMax, LabelName FROM [Sandbox].[kaggle].[Combined_Set_Detection_BBox]\", conn)\n",
    "\n",
    "tmp = bboxes['LabelName'].value_counts()\n",
    "tmp = tmp.apply(np.log10)\n",
    "tmp = tmp.apply(int)\n",
    "\n",
    "class_sets = []\n",
    "\n",
    "for i in range(1,7):\n",
    "    idxs = tmp[tmp == i].index.values\n",
    "    tmp_set = all_classes[all_classes['LabelName'].isin(idxs)]  #reset_index()\n",
    "    tmp_set = tmp_set.reset_index()\n",
    "    tmp_set['LabelID'] = tmp_set.index + 1\n",
    "    class_sets.append(tmp_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model on each partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T21:09:42.881006Z",
     "start_time": "2019-08-15T20:59:22.981630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/nbuser/repo/logs/kaggle20190815T2059/mask_rcnn_kaggle_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 229s 458ms/step - loss: 0.7403 - rpn_class_loss: 0.0124 - rpn_bbox_loss: 0.1822 - mrcnn_class_loss: 0.0739 - mrcnn_bbox_loss: 0.1527 - mrcnn_mask_loss: 0.3191 - val_loss: 2.2910 - val_rpn_class_loss: 0.0976 - val_rpn_bbox_loss: 1.1584 - val_mrcnn_class_loss: 0.1740 - val_mrcnn_bbox_loss: 0.5085 - val_mrcnn_mask_loss: 0.3524\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/mask_rcnn-2.1-py3.5.egg/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Re-starting from epoch 1\n",
      "('/home/nbuser/repo/logs/kaggle20190815T2059/mask_rcnn_kaggle_0001.h5', 0.18666666666666665)\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate' : 0.001,\n",
    "          'epochs' : 25,\n",
    "          'layers' : 'heads',\n",
    "          'mAP_sample_size' : 50,\n",
    "         }\n",
    "\n",
    "for class_set in class_sets:\n",
    "    x = train_on_class_subset(class_set, params)\n",
    "    print(x)\n",
    "    break #only train for the first set\n",
    "\n",
    "\n",
    "\n",
    "# anns = st.load_annotations_by_image(class_set)\n",
    "# train_data = st.load_dataset(anns, DATA_DIR, class_set, is_train=True)\n",
    "# val_data = st.load_dataset(anns, DATA_DIR, class_set, is_train=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "295px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
